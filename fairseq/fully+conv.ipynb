{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from random import choice, randrange\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.argv.append('--dynet_mem')\n",
    "sys.argv.append('6000')\n",
    "\n",
    "embed_size = 64\n",
    "filter_width = 5\n",
    "encoder_depth = 3\n",
    "decoder_depth = 3\n",
    "\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "PAD = \"<PAD>\" #all strings will end with the End Of String token\n",
    "EOS = \"<EOS>\"\n",
    "characters = list(\"abcd\") + [PAD, EOS]\n",
    "\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "\n",
    "def sample_model(min_length, max_lenth):\n",
    "    random_length = randrange(min_length, max_lenth)                             # Pick a random length\n",
    "    random_char_list = [choice(characters[:-2]) for _ in range(random_length)]  # Pick random chars\n",
    "    random_string = ''.join(random_char_list) \n",
    "    return random_string, random_string[::-1]  # Return the random string and its reverse\n",
    "\n",
    "MAX_STRING_LEN = 10\n",
    "\n",
    "train_set = [sample_model(1, MAX_STRING_LEN) for _ in range(3000)]\n",
    "val_set = [sample_model(1, MAX_STRING_LEN) for _ in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import dynet as dy\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def train(network, train_set, val_set, epochs = 20):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        loss = [network.get_loss(input_string, output_string).value() for input_string, output_string in val_set]\n",
    "        return sum(loss)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    trainer = dy.SimpleSGDTrainer(network.model)\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    for i, training_example in enumerate(tqdm(train_set)):\n",
    "        input_string, output_string = training_example\n",
    "        dy.renew_cg()\n",
    "        loss = network.get_loss(input_string, output_string)\n",
    "        loss_value = loss.value()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "\n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%(len(train_set)/100) == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "            print(val_loss)\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    plt.axis([0, 100, 0, len(val_set)*MAX_STRING_LEN])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pp(expr):\n",
    "    print(expr.npvalue().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvAtt:\n",
    "    def params(self, size):\n",
    "        return self.model.add_parameters(size)\n",
    "\n",
    "    def get_conv_filters(self, filter_size, embeddings_size):\n",
    "        f_a = self.params((1, filter_size, embeddings_size, embeddings_size))\n",
    "        b_a = self.params((embeddings_size))\n",
    "        f_b = self.params((1, filter_size, embeddings_size, embeddings_size))\n",
    "        b_b = self.params((embeddings_size))\n",
    "        return f_a, b_a, f_b, b_b\n",
    "\n",
    "    def __init__(self, embeddings_size, filter_size, enc_layers, dec_layers):\n",
    "        self.embeddings_size = embeddings_size\n",
    "\n",
    "        self.model = dy.Model()\n",
    "\n",
    "        self.word_embeddings = self.model.add_lookup_parameters((VOCAB_SIZE, embeddings_size))\n",
    "        self.position_embeddings = self.model.add_lookup_parameters((MAX_STRING_LEN + 2, embeddings_size))\n",
    "\n",
    "        self.enc_filters = []\n",
    "        for _ in range(enc_layers):\n",
    "            f_a, b_a, f_b, b_b = self.get_conv_filters(filter_size, embeddings_size)\n",
    "            self.enc_filters.append((f_a, b_a, f_b, b_b))\n",
    "\n",
    "        self.dec_filters = []\n",
    "        self.att_ws = []\n",
    "        self.att_bs = []\n",
    "        for _ in range(dec_layers):\n",
    "            f_a, b_a, f_b, b_b = self.get_conv_filters(filter_size, embeddings_size)\n",
    "            self.dec_filters.append((f_a, b_a, f_b, b_b))\n",
    "            self.att_ws.append(self.params((embeddings_size, embeddings_size)))\n",
    "            self.att_bs.append(self.params((embeddings_size)))\n",
    "\n",
    "        self.output_w = self.params((VOCAB_SIZE, embeddings_size))\n",
    "        self.output_b = self.params((VOCAB_SIZE))\n",
    "\n",
    "    def GLU(self, A, B):\n",
    "        return dy.cmult(A, dy.tanh(B))\n",
    "\n",
    "    def conv_block(self, f, block_input):\n",
    "        f_a, b_a, f_b, b_b = f\n",
    "\n",
    "        f_a = dy.parameter(f_a)\n",
    "        b_a = dy.parameter(b_a)\n",
    "        f_b = dy.parameter(f_b)\n",
    "        b_b = dy.parameter(b_b)\n",
    "\n",
    "        conv_output_a = dy.conv2d_bias(block_input, f_a, b_a, [1, 1], is_valid=False)\n",
    "        conv_output_b = dy.conv2d_bias(block_input, f_b, b_b, [1, 1], is_valid=False)\n",
    "        conv_output = self.GLU(conv_output_a, conv_output_b)\n",
    "        return conv_output\n",
    "\n",
    "    def embedd(self, string):\n",
    "        seq_len = len(string)\n",
    "        positions = [i for i in range(seq_len)]\n",
    "\n",
    "        embedded_string = [self.word_embeddings[char] for char in string]\n",
    "        embedded_positions = [self.position_embeddings[pos] for pos in positions]\n",
    "\n",
    "        embedded = [char + pos for char, pos in zip(embedded_string, embedded_positions)]\n",
    "        return embedded, seq_len\n",
    "\n",
    "    def encode(self, input_string):\n",
    "        embedded, seq_len = self.embedd(input_string)\n",
    "        conv_input = dy.reshape(dy.concatenate_cols(embedded), (1, seq_len, self.embeddings_size))\n",
    "\n",
    "        for enc_filter in self.enc_filters:\n",
    "            conv_input = self.conv_block(enc_filter, conv_input) + conv_input\n",
    "        return conv_input[0]\n",
    "\n",
    "    def step_attention(self, conv_block_out, encoded, w, b, last_w, seq_len):\n",
    "        w = dy.parameter(w)\n",
    "        b = dy.parameter(b)\n",
    "        conv_block_out = conv_block_out[0]\n",
    "        # TODO replace with conv\n",
    "        ds = [w * h + b + last_w for h in conv_block_out]\n",
    "        aij = [dy.softmax(dy.concatenate([dy.transpose(d) * z for z in encoded])) for d in ds]\n",
    "\n",
    "        cs = [dy.esum([z * a for a, z in zip(ai, encoded)]) for ai in aij]\n",
    "        cs = dy.reshape(dy.transpose(dy.concatenate_cols(cs)), (1, seq_len, self.embeddings_size))\n",
    "        return cs\n",
    "\n",
    "    def decode(self, current_out, encoded):\n",
    "        embedded, seq_len = self.embedd(current_out)\n",
    "        last_w = embedded[-1]\n",
    "        conv_input = dy.reshape(dy.concatenate_cols(embedded), (1, seq_len, self.embeddings_size))\n",
    "\n",
    "        for dec_filter, att_w, att_b in zip(self.dec_filters, self.att_ws, self.att_bs):\n",
    "            conv_block_out = self.conv_block(dec_filter, conv_input)\n",
    "            conv_input = self.step_attention(conv_block_out, encoded, att_w, att_b, last_w, seq_len) + conv_input\n",
    "        return conv_input\n",
    "\n",
    "    def str2ints(self, string):\n",
    "        return [char2int[c] for c in [PAD] + list(string) + [EOS]]\n",
    "\n",
    "    def get_loss(self, input_string, output_string):\n",
    "        input_string = self.str2ints(input_string)\n",
    "        output_string = self.str2ints(output_string)\n",
    "\n",
    "        w = dy.parameter(self.output_w)\n",
    "        b = dy.parameter(self.output_b)\n",
    "\n",
    "        encoded = self.encode(input_string)\n",
    "\n",
    "        loss = []\n",
    "        for j in range(1, len(output_string)):\n",
    "            decoded = self.decode(output_string[:j], encoded)\n",
    "            probs = dy.softmax(w * decoded[0][-1] + b)\n",
    "            loss.append(-dy.log(dy.pick(probs, output_string[j])))\n",
    "        decoded = self.decode(output_string, encoded)\n",
    "        probs = dy.softmax(w * decoded[0][-1] + b)\n",
    "        loss.append(-dy.log(dy.pick(probs, char2int[PAD])))\n",
    "        return dy.esum(loss)\n",
    "\n",
    "    def generate(self, input_string):\n",
    "        input_string = self.str2ints(input_string)\n",
    "\n",
    "        w = dy.parameter(self.output_w)\n",
    "        b = dy.parameter(self.output_b)\n",
    "\n",
    "        encoded = self.encode(input_string)\n",
    "        output_string = [char2int[PAD]]\n",
    "        for _ in range(MAX_STRING_LEN+2):\n",
    "            decoded = self.decode(output_string, encoded)\n",
    "            probs = dy.softmax(w * decoded[0][-1] + b)\n",
    "            next_char = np.argmax(probs.npvalue())\n",
    "            output_string.append(next_char)\n",
    "            if int2char[next_char] == EOS:\n",
    "                break\n",
    "            \n",
    "        return [int2char[char] for char in output_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "conv = ConvAtt(embed_size, filter_width, encoder_depth, decoder_depth)\n",
    "print(conv.generate('ab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b302ed87d84523a81fc57fe1dc48a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1077.915850162506\n",
      "707.7158609628677\n",
      "711.1349729351932\n",
      "631.3835091533019\n"
     ]
    }
   ],
   "source": [
    "train(conv, train_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from slackclient import SlackClient\n",
    "\n",
    "def get_val_set_loss(network, val_set):\n",
    "    loss = [network.get_loss(input_string, output_string).value() for input_string, output_string in val_set]\n",
    "    return sum(loss)\n",
    "sc = SlackClient(token)\n",
    "sc.api_call(str(get_val_set_loss(conv, val_set)))\n",
    "sc.api_call(conv.generate('abcdab'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', 'a', 'a', 'c', 'a', 'c', '<PAD>', 'a', 'a', '<PAD>', 'c', 'a', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(conv.generate('bcaa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
