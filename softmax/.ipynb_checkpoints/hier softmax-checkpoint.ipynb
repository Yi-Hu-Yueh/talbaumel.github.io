{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling-Up Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are familiar with sequence to sequence models let’s discuss  how to scale them to real world problems. In the previous example we used a very small vocabulary (4 symbols $“a,b,c,d”$)  but when dealing with tasks such as automatic machine translation our vocabulary can contain thousands of unique words, that means that the last layer of our network must be the dimension as the size of the vocabulary and $softmax$ must be applied on an extremely long vector. When training a network we cannot afford such a costly operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's why hierarchical softmax was invented, it can increase softmax time by up to $log(n)$ without adding compromising too much of the network reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax function, or normalized exponential is used to transform a $n$ dimensional vector into a probabilty over $n$ classes, formaly it is defined as: $P(class=i | x) = \\dfrac{e^{x_i}}{\\sum_{j=1}^ne^{x_j}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy code for SoftMax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the softmax we need to $O(n)$ time. Let's see how can we reduce it to $O(log(n))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hierarchical Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hierarchical softmax function first arranges the output vocabulary in an hierarchical tree (we will discuss later how this tree can be constructed). Once we constructed the tree we can use softmax to select each branch of the tree. For example, given the following hierarchy and the value of the last hidden layer is $V$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/HierSoftMax.jpg\" width=\"25%\" height=\"25%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilty of the network to predict \"D\" is (the probabilty of choosing the 2nd branch in $B_1$)*(the provavilty of choosing the 1st branch on $B_3$). More formally:  $P(class=D | V) = softmax(V \\times W_{B_1})_1*softmax(V \\times W_{B_3})_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what is hierarchical softmax we can start implementing it. We will create an hier_softmax that will recieve an output hierarchy and will be able to calculate of the probabilty of an output given $V$ and to generate to most likely output given a vector $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will define some auxiliary functions to handle trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from copy import copy\n",
    "\n",
    "def _get_subtrees(tree):\n",
    "    yield tree\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == list:\n",
    "            for x in _get_subtrees(subtree):\n",
    "                yield x\n",
    "\n",
    "\n",
    "# Returns pairs of paths and leafves of a tree\n",
    "def _get_leaves_paths(tree):\n",
    "    for i, subtree in enumerate(tree):\n",
    "        if type(subtree) == list:\n",
    "            for path, value in _get_leaves_paths(subtree):\n",
    "                yield [i] + path, value\n",
    "        else:\n",
    "            yield [i], subtree\n",
    "\n",
    "\n",
    "# Returns the number of nodes in a tree (not including root)\n",
    "def _count_nodes(tree):\n",
    "    size = 0\n",
    "    for node in tree:\n",
    "        if type(node) == list:\n",
    "            size += 1 + _count_nodes(node)\n",
    "    return size\n",
    "\n",
    "\n",
    "# Returns all the nodes in a path\n",
    "def _get_nodes(tree, path):\n",
    "    next_node = 0\n",
    "    nodes = []\n",
    "    for decision in path:\n",
    "        nodes.append(next_node)\n",
    "        next_node += 1 + _count_nodes(tree[:decision])\n",
    "        tree = tree[decision]\n",
    "    return nodes\n",
    "\n",
    "\n",
    "# turns a list to a binary tree\n",
    "def random_binary_full_tree(outputs):\n",
    "    outputs = copy(outputs)\n",
    "    shuffle(outputs)\n",
    "\n",
    "    while len(outputs) > 2:\n",
    "        temp_outputs = []\n",
    "        for i in range(0, len(outputs), 2):\n",
    "            if len(outputs) - (i+1) > 0:\n",
    "                temp_outputs.append([outputs[i], outputs[i+1]])\n",
    "            else:\n",
    "                temp_outputs.append(outputs[i])\n",
    "        outputs = temp_outputs\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the auxiliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tree: [[[[[[41, 48], [25, 4]], [[44, 45], [9, 18]]], [[[15, 31], [30, 35]], [[32, 8], [33, 6]]]], [[[[3, 28], [14, 7]], [[42, 16], [10, 39]]], [[[23, 24], [27, 1]], [[26, 46], [40, 37]]]]], [[[[[2, 12], [34, 21]], [[19, 5], [49, 17]]], [[[38, 22], [43, 29]], [[20, 36], [13, 47]]]], [11, 0]]]\n",
      "All subtrees:\n",
      "\t[[[[[[41, 48], [25, 4]], [[44, 45], [9, 18]]], [[[15, 31], [30, 35]], [[32, 8], [33, 6]]]], [[[[3, 28], [14, 7]], [[42, 16], [10, 39]]], [[[23, 24], [27, 1]], [[26, 46], [40, 37]]]]], [[[[[2, 12], [34, 21]], [[19, 5], [49, 17]]], [[[38, 22], [43, 29]], [[20, 36], [13, 47]]]], [11, 0]]]\n",
      "\t[[[[[41, 48], [25, 4]], [[44, 45], [9, 18]]], [[[15, 31], [30, 35]], [[32, 8], [33, 6]]]], [[[[3, 28], [14, 7]], [[42, 16], [10, 39]]], [[[23, 24], [27, 1]], [[26, 46], [40, 37]]]]]\n",
      "\t[[[[41, 48], [25, 4]], [[44, 45], [9, 18]]], [[[15, 31], [30, 35]], [[32, 8], [33, 6]]]]\n",
      "\t[[[41, 48], [25, 4]], [[44, 45], [9, 18]]]\n",
      "\t[[41, 48], [25, 4]]\n",
      "\t[41, 48]\n",
      "\t[25, 4]\n",
      "\t[[44, 45], [9, 18]]\n",
      "\t[44, 45]\n",
      "\t[9, 18]\n",
      "\t[[[15, 31], [30, 35]], [[32, 8], [33, 6]]]\n",
      "\t[[15, 31], [30, 35]]\n",
      "\t[15, 31]\n",
      "\t[30, 35]\n",
      "\t[[32, 8], [33, 6]]\n",
      "\t[32, 8]\n",
      "\t[33, 6]\n",
      "\t[[[[3, 28], [14, 7]], [[42, 16], [10, 39]]], [[[23, 24], [27, 1]], [[26, 46], [40, 37]]]]\n",
      "\t[[[3, 28], [14, 7]], [[42, 16], [10, 39]]]\n",
      "\t[[3, 28], [14, 7]]\n",
      "\t[3, 28]\n",
      "\t[14, 7]\n",
      "\t[[42, 16], [10, 39]]\n",
      "\t[42, 16]\n",
      "\t[10, 39]\n",
      "\t[[[23, 24], [27, 1]], [[26, 46], [40, 37]]]\n",
      "\t[[23, 24], [27, 1]]\n",
      "\t[23, 24]\n",
      "\t[27, 1]\n",
      "\t[[26, 46], [40, 37]]\n",
      "\t[26, 46]\n",
      "\t[40, 37]\n",
      "\t[[[[[2, 12], [34, 21]], [[19, 5], [49, 17]]], [[[38, 22], [43, 29]], [[20, 36], [13, 47]]]], [11, 0]]\n",
      "\t[[[[2, 12], [34, 21]], [[19, 5], [49, 17]]], [[[38, 22], [43, 29]], [[20, 36], [13, 47]]]]\n",
      "\t[[[2, 12], [34, 21]], [[19, 5], [49, 17]]]\n",
      "\t[[2, 12], [34, 21]]\n",
      "\t[2, 12]\n",
      "\t[34, 21]\n",
      "\t[[19, 5], [49, 17]]\n",
      "\t[19, 5]\n",
      "\t[49, 17]\n",
      "\t[[[38, 22], [43, 29]], [[20, 36], [13, 47]]]\n",
      "\t[[38, 22], [43, 29]]\n",
      "\t[38, 22]\n",
      "\t[43, 29]\n",
      "\t[[20, 36], [13, 47]]\n",
      "\t[20, 36]\n",
      "\t[13, 47]\n",
      "\t[11, 0]\n",
      "All paths and leaves:\n",
      "\t([0, 0, 0, 0, 0, 0], 41)\n",
      "\t([0, 0, 0, 0, 0, 1], 48)\n",
      "\t([0, 0, 0, 0, 1, 0], 25)\n",
      "\t([0, 0, 0, 0, 1, 1], 4)\n",
      "\t([0, 0, 0, 1, 0, 0], 44)\n",
      "\t([0, 0, 0, 1, 0, 1], 45)\n",
      "\t([0, 0, 0, 1, 1, 0], 9)\n",
      "\t([0, 0, 0, 1, 1, 1], 18)\n",
      "\t([0, 0, 1, 0, 0, 0], 15)\n",
      "\t([0, 0, 1, 0, 0, 1], 31)\n",
      "\t([0, 0, 1, 0, 1, 0], 30)\n",
      "\t([0, 0, 1, 0, 1, 1], 35)\n",
      "\t([0, 0, 1, 1, 0, 0], 32)\n",
      "\t([0, 0, 1, 1, 0, 1], 8)\n",
      "\t([0, 0, 1, 1, 1, 0], 33)\n",
      "\t([0, 0, 1, 1, 1, 1], 6)\n",
      "\t([0, 1, 0, 0, 0, 0], 3)\n",
      "\t([0, 1, 0, 0, 0, 1], 28)\n",
      "\t([0, 1, 0, 0, 1, 0], 14)\n",
      "\t([0, 1, 0, 0, 1, 1], 7)\n",
      "\t([0, 1, 0, 1, 0, 0], 42)\n",
      "\t([0, 1, 0, 1, 0, 1], 16)\n",
      "\t([0, 1, 0, 1, 1, 0], 10)\n",
      "\t([0, 1, 0, 1, 1, 1], 39)\n",
      "\t([0, 1, 1, 0, 0, 0], 23)\n",
      "\t([0, 1, 1, 0, 0, 1], 24)\n",
      "\t([0, 1, 1, 0, 1, 0], 27)\n",
      "\t([0, 1, 1, 0, 1, 1], 1)\n",
      "\t([0, 1, 1, 1, 0, 0], 26)\n",
      "\t([0, 1, 1, 1, 0, 1], 46)\n",
      "\t([0, 1, 1, 1, 1, 0], 40)\n",
      "\t([0, 1, 1, 1, 1, 1], 37)\n",
      "\t([1, 0, 0, 0, 0, 0], 2)\n",
      "\t([1, 0, 0, 0, 0, 1], 12)\n",
      "\t([1, 0, 0, 0, 1, 0], 34)\n",
      "\t([1, 0, 0, 0, 1, 1], 21)\n",
      "\t([1, 0, 0, 1, 0, 0], 19)\n",
      "\t([1, 0, 0, 1, 0, 1], 5)\n",
      "\t([1, 0, 0, 1, 1, 0], 49)\n",
      "\t([1, 0, 0, 1, 1, 1], 17)\n",
      "\t([1, 0, 1, 0, 0, 0], 38)\n",
      "\t([1, 0, 1, 0, 0, 1], 22)\n",
      "\t([1, 0, 1, 0, 1, 0], 43)\n",
      "\t([1, 0, 1, 0, 1, 1], 29)\n",
      "\t([1, 0, 1, 1, 0, 0], 20)\n",
      "\t([1, 0, 1, 1, 0, 1], 36)\n",
      "\t([1, 0, 1, 1, 1, 0], 13)\n",
      "\t([1, 0, 1, 1, 1, 1], 47)\n",
      "\t([1, 1, 0], 11)\n",
      "\t([1, 1, 1], 0)\n",
      "Number of nodes in the tree: 48\n",
      "all nodes in path [0, 0, 0, 0]:\n",
      "\t0\n",
      "\t1\n",
      "\t2\n",
      "\t3\n"
     ]
    }
   ],
   "source": [
    "tree = random_binary_full_tree(range(50))\n",
    "print 'Our tree:',tree\n",
    "\n",
    "print 'All subtrees:'\n",
    "for subtree in _get_subtrees(tree):\n",
    "    print '\\t',subtree\n",
    "\n",
    "print 'All paths and leaves:'\n",
    "for subtree in _get_leaves_paths(tree):\n",
    "    print '\\t',subtree\n",
    "    \n",
    "print 'Number of nodes in the tree:',_count_nodes(tree)\n",
    "\n",
    "print 'all nodes in path [0, 0, 0, 0]:'\n",
    "for nodes in _get_nodes(tree, [0, 0, 0, 0]):\n",
    "    print '\\t',nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hier softmax class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv.append('--cnn-mem')\n",
    "sys.argv.append('2000')\n",
    "import pycnn as pc\n",
    "\n",
    "class hier_softmax:\n",
    "    def __init__(self, tree, contex_size, model):\n",
    "        #create a weight matrix and bias vector for each node in the tree\n",
    "        for i, subtree in enumerate(_get_subtrees(tree)):\n",
    "            model.add_parameters(\"softmax_node_\"+str(i)+\"_w\", (len(subtree), contex_size))\n",
    "            model.add_parameters(\"softmax_node_\" + str(i) + \"_b\", len(subtree))\n",
    "        \n",
    "        #create a dictionary from each value to its path\n",
    "        value_to_path_and_nodes_dict = {}\n",
    "        for path, value in _get_leaves_paths(tree):\n",
    "            nodes = _get_nodes(tree, path)\n",
    "            value_to_path_and_nodes_dict[char2int[value]] = path, nodes\n",
    "        self.value_to_path_and_nodes_dict = value_to_path_and_nodes_dict\n",
    "        self.model = model\n",
    "        self.tree = tree\n",
    "    \n",
    "    #get the loss on a given value (for training)\n",
    "    def get_loss(self, context, value):\n",
    "        loss = []\n",
    "        path, nodes = self.value_to_path_and_nodes_dict[value]\n",
    "        for p, n in zip(path, nodes):\n",
    "            w = pc.parameter(self.model[\"softmax_node_\"+str(n)+\"_w\"])\n",
    "            b = pc.parameter(self.model[\"softmax_node_\" + str(n) + \"_b\"])\n",
    "            probs = pc.softmax(w*context+b)\n",
    "            loss.append(-pc.log(pc.pick(probs, p)))\n",
    "        return pc.esum(loss)\n",
    "\n",
    "    #get the most likely\n",
    "    def generate(self, context):\n",
    "        best_value = None\n",
    "        best_loss = float(100000)\n",
    "        for value in self.value_to_path_and_nodes_dict:\n",
    "            loss = self.get_loss(context, value)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_value = value\n",
    "        return best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the performance improvement we can get from the hier_softmax. Again, we will learn the reverse function, but this time on a big vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('120 53 316 502', '502 316 53 120')\n"
     ]
    }
   ],
   "source": [
    "from random import choice, randrange\n",
    "\n",
    "EOS = \"<EOS>\" #all strings will end with the End Of String token\n",
    "characters = [str(i) for i in range(1000)]\n",
    "characters.append(EOS)\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "\n",
    "def sample_model(min_length, max_lenth):\n",
    "    random_length = randrange(min_length, max_lenth)                             # Pick a random length\n",
    "    random_char_list = [choice(characters[:-1]) for _ in xrange(random_length)]  # Pick random chars\n",
    "    random_string = ' '.join(random_char_list)\n",
    "    reverse_string = ' '.join(random_char_list[::-1])\n",
    "    return random_string, reverse_string  # Return the random string and its reverse\n",
    "\n",
    "print sample_model(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "MAX_STRING_LEN = 5\n",
    "\n",
    "train_set = [sample_model(1, MAX_STRING_LEN) for _ in xrange(3000)]\n",
    "val_set = [sample_model(1, MAX_STRING_LEN) for _ in xrange(50)]\n",
    "\n",
    "def train(network, train_set, val_set, epochs = 20):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        loss = [network.get_loss(input_string, output_string).value() for input_string, output_string in val_set]\n",
    "        return sum(loss)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    trainer = pc.SimpleSGDTrainer(network.model)\n",
    "    start = datetime.now()\n",
    "    for i, training_example in enumerate(train_set):\n",
    "        input_string, output_string = training_example\n",
    "        \n",
    "        loss = network.get_loss(input_string, output_string)\n",
    "        loss_value = loss.value()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "    print datetime.now()-start\n",
    "        \n",
    "\n",
    "    print 'loss on validation set:', get_val_set_loss(network, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a large vocab data we can measure the training time of the attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import AttentionNetwork\n",
    "\n",
    "ENC_RNN_NUM_OF_LAYERS = 1\n",
    "DEC_RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 200\n",
    "ENC_STATE_SIZE = 210\n",
    "DEC_STATE_SIZE = 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:08:03.864231\n",
      "loss on validation set: 2.18331918505\n"
     ]
    }
   ],
   "source": [
    "att = AttentionNetwork(ENC_RNN_NUM_OF_LAYERS, DEC_RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, ENC_STATE_SIZE, DEC_STATE_SIZE)\n",
    "\n",
    "train(att, train_set, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add hierarchical softmax to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_tree = random_binary_full_tree(characters)\n",
    "\n",
    "RNN_BUILDER = pc.LSTMBuilder\n",
    "class AttentionNetworkWithHierSoftmax(AttentionNetwork):\n",
    "    def __init__(self, enc_layers, dec_layers, embeddings_size, enc_state_size, dec_state_size, tree):\n",
    "        self.model = pc.Model()\n",
    "\n",
    "        # the embedding paramaters\n",
    "        self.model.add_lookup_parameters(\"lookup\", (VOCAB_SIZE, embeddings_size))\n",
    "\n",
    "        # the rnns\n",
    "        self.ENC_RNN = RNN_BUILDER(enc_layers, embeddings_size, enc_state_size, self.model)\n",
    "        self.DEC_RNN = RNN_BUILDER(dec_layers, enc_state_size, dec_state_size, self.model)\n",
    "        \n",
    "        # attention weights\n",
    "        self.model.add_parameters(\"attention_w1\", (enc_state_size, enc_state_size))\n",
    "        self.model.add_parameters(\"attention_w2\", (enc_state_size, dec_state_size))\n",
    "        self.model.add_parameters(\"attention_v\", (1, enc_state_size))\n",
    "\n",
    "        self.enc_state_size = enc_state_size\n",
    "        \n",
    "        self.tree = tree\n",
    "        self.hier_softmax = hier_softmax(tree, dec_state_size, self.model)\n",
    "    \n",
    "    def _get_probs(self, rnn_output, output_char):\n",
    "        return self.hier_softmax.get_loss(rnn_output, output_char)\n",
    "    \n",
    "    def _predict(self, rnn_output):\n",
    "        return self.self.hier_softmax.generate(rnn_output)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:07:23.806474\n",
      "loss on validation set: 1.41154876177\n"
     ]
    }
   ],
   "source": [
    "att = AttentionNetworkWithHierSoftmax(\n",
    "    ENC_RNN_NUM_OF_LAYERS, DEC_RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, ENC_STATE_SIZE, DEC_STATE_SIZE, output_tree)\n",
    "\n",
    "train(att, train_set, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has we can see the hierarchical softmax shaved almost 12.5% off our training time. On real world data a vocabulary of 1,000 words is considered tiny so the gain should be considerably higher. Other difference from real data is that the training examples are not uniformly distributed and external information (such as wordnet) can further improve the hier softmax performance (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.8829&rep=rep1&type=pdf#page=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "About me: https://www.cs.bgu.ac.il/~talbau/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
