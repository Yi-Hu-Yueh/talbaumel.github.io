{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from random import choice, randrange\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "EOS = \"<EOS>\" #all strings will end with the End Of String token\n",
    "PAD = \"<PAD>\"\n",
    "characters = list(\"abcd\")\n",
    "characters.append(EOS)\n",
    "characters.append(PAD)\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "PAD_IDX = VOCAB_SIZE - 1\n",
    "\n",
    "def sample_model(min_length, max_lenth):\n",
    "    random_length = randrange(min_length, max_lenth)                             # Pick a random length\n",
    "    random_char_list = [choice(characters[:-2]) for _ in range(random_length)]  # Pick random chars\n",
    "    random_string = ''.join(random_char_list) \n",
    "    return random_string, random_string[::-1]  # Return the random string and its reverse\n",
    "    \n",
    "\n",
    "MIN_STRING_LEN = 1\n",
    "MAX_STRING_LEN = 10\n",
    "TRAIN_SET_SIZE = 5000\n",
    "VAL_SET_SIZE = 10\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 4\n",
    "STATE_SIZE = 64\n",
    "\n",
    "default_epochs = 50\n",
    "\n",
    "use_gpu = False\n",
    "\n",
    "train_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(TRAIN_SET_SIZE)]\n",
    "val_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(VAL_SET_SIZE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_string(strings):\n",
    "    batch_size = len(strings)\n",
    "\n",
    "    strings_with_eos = [list(string) + [EOS] for string in strings]\n",
    "    max_len = max([len(string) for string in strings_with_eos])\n",
    "    padded_strings = [string + [PAD] * (max_len - len(string)) for string in strings_with_eos]\n",
    "    #len_first = [[padded_strings[j][i]for j in range(batch_size)] for i in range(max_len)]\n",
    "    #int_strings = [[char2int[c] for c in string] for string in len_first]\n",
    "    int_strings = [[char2int[c] for c in string] for string in padded_strings]\n",
    "    var = Variable(torch.LongTensor(int_strings))\n",
    "    if use_gpu: return var.cuda()\n",
    "    return var\n",
    "\n",
    "def get_loss(network, input_strings, output_strings):\n",
    "    batch_size = len(output_strings)\n",
    "    input_strings_t = _preprocess_string(input_strings)\n",
    "    output_strings_t = _preprocess_string(output_strings)\n",
    "\n",
    "    probs = network(input_strings_t, batch_size).permute(1, 0, 2)\n",
    "\n",
    "    loss = sum([F.cross_entropy(p, t, ignore_index=PAD_IDX) for p, t in zip(probs, output_strings_t)])\n",
    "\n",
    "    return loss\n",
    "\n",
    "def generate(network, input_string):\n",
    "    input_string = _preprocess_string([input_string])\n",
    "    probs = network(input_string, 1)\n",
    "    generated = [int2char[prob[0].topk(1)[1][0]] for prob in probs.data]\n",
    "    return (''.join(generated)).split(EOS)[0].replace(PAD, '')\n",
    "\n",
    "def batcher(dataset, epochs = 1):\n",
    "    sources, targets = [], []\n",
    "    i = 0\n",
    "    for _ in range(epochs):\n",
    "        for source, target in dataset:\n",
    "            i+=1\n",
    "            sources.append(source), targets.append(target)\n",
    "            if len(sources) >= batch_size:\n",
    "                yield sources, targets\n",
    "                sources, targets = [], []\n",
    "    if sources: yield sources, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(network, train_set, val_set, epochs=default_epochs):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        losses = [get_loss(network, input_strings, output_strings).data[0]\n",
    "                 for input_strings, output_strings in batcher(val_set)]\n",
    "        return sum(losses)\n",
    "    if use_gpu: network.cuda()\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    optim = torch.optim.Adam(network.parameters())\n",
    "    \n",
    "    total_iterations = max(int((len(train_set)*epochs)/batch_size), 100)\n",
    "    for i, (input_strings, output_strings) in enumerate(tqdm(batcher(train_set, epochs=epochs))):\n",
    "              \n",
    "        optim.zero_grad()\n",
    "        loss = get_loss(network, input_strings, output_strings)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "            \n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%int(total_iterations/100) == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    #plt.axis([0, 100, 0, 100])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class SimpleRNNNetwork(nn.Module):\n",
    "    def __init__(self,num_of_layers, embeddings_size, state_size):\n",
    "        super(SimpleRNNNetwork, self).__init__()\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        # the embedding paramaters\n",
    "        self.embeddings = nn.Embedding(VOCAB_SIZE, embeddings_size, padding_idx=PAD_IDX)\n",
    "\n",
    "        # the rnn\n",
    "        self.RNN = nn.LSTM(embeddings_size, state_size, num_of_layers)\n",
    "        \n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.linear = nn.Linear(state_size, VOCAB_SIZE)    \n",
    "        \n",
    "    def lstm_init_func(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        c0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        if use_gpu: return h0.cuda(), c0.cuda()\n",
    "        return h0,c0\n",
    "    \n",
    "    def forward(self, input_string, batch_size):                        \n",
    "        embedded = self.embeddings(input_string.permute(1, 0))\n",
    "        output, hn = self.RNN(embedded, self.lstm_init_func(batch_size))\n",
    "        output = output\n",
    "        logits = self.linear(output)\n",
    "        return logits #F.log_softmax(logits, 2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_net = SimpleRNNNetwork(RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "#train(lstm_net, train_set, val_set)\n",
    "#print(generate(lstm_net, 'abc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     13,
     19
    ]
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderNetwork(nn.Module):\n",
    "    def __init__(self, num_of_layers, embeddings_size, state_size):\n",
    "        super(EncoderDecoderNetwork, self).__init__()\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        self.embeddings = nn.Embedding(VOCAB_SIZE, embeddings_size, padding_idx=PAD_IDX)\n",
    "\n",
    "        self.enc = nn.LSTM(embeddings_size, state_size, num_of_layers)\n",
    "        self.dec = nn.LSTM(state_size, state_size, num_of_layers)\n",
    "        \n",
    "        self.linear = nn.Linear(state_size, VOCAB_SIZE)\n",
    "    \n",
    "    def get_rnn_init_state(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        c0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        if use_gpu: return h0.cuda(), c0.cuda()\n",
    "        return h0, c0\n",
    "    \n",
    "    def encode(self, encoder_outputs, decoder_state):\n",
    "        return encoder_outputs[-1].unsqueeze(0)\n",
    "    \n",
    "    def forward(self, input_string, batch_size):\n",
    "        embedded = self.embeddings(input_string.permute(1, 0))\n",
    "        encoder_outputs, hn = self.enc(embedded, self.get_rnn_init_state(batch_size))\n",
    "        \n",
    "        hidden = self.get_rnn_init_state(batch_size)\n",
    "        \n",
    "        outputs = []\n",
    "        for _ in range(len(embedded)):\n",
    "            encoded = self.encode(encoder_outputs, hidden[0])\n",
    "            output, hidden = self.dec(encoded, hidden)\n",
    "            outputs.append(output)\n",
    "        logits = self.linear(torch.cat(outputs, 0))\n",
    "\n",
    "        return logits #F.log_softmax(logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_decoder = EncoderDecoderNetwork(RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "#train(encoder_decoder, train_set, val_set)\n",
    "#print(generate(encoder_decoder, 'abcd'))\n",
    "#print(generate(encoder_decoder, 'abcdabcdabcdabcd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderAttentionNetwork(EncoderDecoderNetwork):\n",
    "    def __init__(self, num_of_layers, embeddings_size, state_size):\n",
    "        super(EncoderDecoderAttentionNetwork, self).__init__(num_of_layers, embeddings_size, state_size)\n",
    "        # the attention\n",
    "        self.att_w1 = nn.Linear(state_size, state_size, bias=False)\n",
    "        self.att_w2 = nn.Linear(state_size, state_size)\n",
    "        self.att_v = nn.Linear(state_size, 1)\n",
    "\n",
    "    def encode(self, encoder_outputs, decoder_state):\n",
    "        decoder_state = decoder_state[-1].unsqueeze(0) # Use only the last layer\n",
    "        unnormalized_att = self.att_v(F.tanh(self.att_w1(decoder_state) + self.att_w2(encoder_outputs)))\n",
    "        #att = F.softmax(unnormalized_att)\n",
    "        att = F.softmax(unnormalized_att.permute(1,0,2), dim=1).permute(1,0,2)\n",
    "        attended = encoder_outputs.mul(att).sum(0)\n",
    "        return attended.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#att = EncoderDecoderAttentionNetwork(RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "#train(att, train_set, val_set)\n",
    "#print(generate(att, 'abcdabcdabcdabcd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     38
    ]
   },
   "outputs": [],
   "source": [
    "class AttentionNetworkWithPrint(EncoderDecoderAttentionNetwork):\n",
    "    def __init__(self, num_of_layers, embeddings_size, state_size):\n",
    "        super(AttentionNetworkWithPrint, self).__init__(num_of_layers, embeddings_size, state_size)\n",
    "\n",
    "        self.should_print = False\n",
    "        self.att_mat = []\n",
    "    \n",
    "    def encode(self, encoder_outputs, decoder_state):\n",
    "        unnormalized_att = self.att_v(F.tanh(self.att_w1(decoder_state) + self.att_w2(encoder_outputs)))\n",
    "        att = F.softmax(unnormalized_att.permute(1,0,2), dim=1).permute(1,0,2)\n",
    "        if self.should_print:\n",
    "            self.att_mat.append(att.data.numpy())\n",
    "        attended = encoder_outputs.mul(att).sum(0)\n",
    "        return attended.unsqueeze(0)\n",
    "    \n",
    "    def _plot_attention(self, matrix, max_weight=None, ax=None):\n",
    "        \"\"\"Draw Hinton diagram for visualizing a weight matrix.\"\"\"\n",
    "        ax = ax if ax is not None else plt.gca()\n",
    "\n",
    "        if not max_weight:\n",
    "            max_weight = 2**np.ceil(np.log(np.abs(matrix).max())/np.log(2))\n",
    "\n",
    "        ax.patch.set_facecolor('gray')\n",
    "        ax.set_aspect('equal', 'box')\n",
    "        ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "        ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "        for (x, y, _, _), w in np.ndenumerate(matrix):\n",
    "            color = 'white' if w > 0 else 'black'\n",
    "            size = np.sqrt(np.abs(w))\n",
    "            rect = plt.Rectangle([x - size / 2, y - size / 2], size, size,\n",
    "                                 facecolor=color, edgecolor=color)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        ax.autoscale_view()\n",
    "        ax.invert_yaxis()\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_and_plot_attention(self, input_string):\n",
    "        self.should_print = True\n",
    "        self.att_mat = []\n",
    "        output_string = generate(self, input_string)\n",
    "\n",
    "        self._plot_attention(np.array(self.att_mat))\n",
    "        att.should_print = False\n",
    "        att.att_mat = []\n",
    "        return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:01, 19.71it/s]"
     ]
    }
   ],
   "source": [
    "att = AttentionNetworkWithPrint(RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train(att, train_set, val_set)\n",
    "print(att.generate_and_plot_attention('abc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    train(att, train_set, val_set, 1)\n",
    "    print(att.generate_and_plot_attention('abc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
