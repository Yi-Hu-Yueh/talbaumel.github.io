{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyNet vs PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from random import choice, randrange\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "EOS = \"<EOS>\" #all strings will end with the End Of String token\n",
    "PAD = \"<PAD>\"\n",
    "characters = list(\"abcd\")\n",
    "characters.append(EOS)\n",
    "characters.append(PAD)\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "PAD_IDX = VOCAB_SIZE - 1\n",
    "\n",
    "def sample_model(min_length, max_lenth):\n",
    "    random_length = randrange(min_length, max_lenth)                             # Pick a random length\n",
    "    random_char_list = [choice(characters[:-2]) for _ in range(random_length)]  # Pick random chars\n",
    "    random_string = ''.join(random_char_list) \n",
    "    return random_string, random_string[::-1]  # Return the random string and its reverse\n",
    "    \n",
    "\n",
    "MIN_STRING_LEN = 1\n",
    "MAX_STRING_LEN = 10\n",
    "TRAIN_SET_SIZE = 5000\n",
    "VAL_SET_SIZE = 10\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 4\n",
    "STATE_SIZE = 64\n",
    "\n",
    "default_epochs = 20\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(TRAIN_SET_SIZE)]\n",
    "val_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(VAL_SET_SIZE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyNet Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import dynet as dy\n",
    "from tqdm import tqdm\n",
    "def train_dynet(network, train_set, val_set, epochs = default_epochs):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        loss = [network.get_loss(input_string, output_string).value() for input_string, output_string in val_set]\n",
    "        return sum(loss)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    trainer = dy.SimpleSGDTrainer(network.model, learning_rate=learning_rate)\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    for i, training_example in enumerate(tqdm(train_set)):\n",
    "        input_string, output_string = training_example\n",
    "        \n",
    "        loss = network.get_loss(input_string, output_string)\n",
    "        loss_value = loss.value()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "\n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%(len(train_set)/100) == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    #plt.axis([0, 100, 0, len(val_set)*MAX_STRING_LEN])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class AttentionDyNet():\n",
    "    def __init__(self, embeddings_size, state_size):\n",
    "        self.model = dy.ParameterCollection()\n",
    "\n",
    "        # the embedding paramaters\n",
    "        self.embeddings = self.model.add_lookup_parameters((VOCAB_SIZE, embeddings_size))\n",
    "\n",
    "        # the rnns\n",
    "        self.ENC_RNN = dy.LSTMBuilder(1, embeddings_size, state_size, self.model)\n",
    "        self.DEC_RNN = dy.LSTMBuilder(1, state_size, state_size, self.model)\n",
    "\n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.output_w = self.model.add_parameters((VOCAB_SIZE, state_size))\n",
    "        self.output_b = self.model.add_parameters((VOCAB_SIZE))\n",
    "\n",
    "        # attention weights\n",
    "        self.attention_w1 = self.model.add_parameters((state_size, state_size))\n",
    "        self.attention_w2 = self.model.add_parameters((state_size, state_size))\n",
    "        self.attention_v = self.model.add_parameters((1, state_size))\n",
    "\n",
    "        self.state_size = state_size\n",
    "        \n",
    "    def _add_eos(self, string):\n",
    "        string = list(string) + [EOS]\n",
    "        return [char2int[c] for c in string]\n",
    "    \n",
    "    def _embed_string(self, string):\n",
    "        return [self.embeddings[char] for char in string]\n",
    "\n",
    "    def _run_rnn(self, init_state, input_vecs):\n",
    "        s = init_state\n",
    "\n",
    "        states = s.add_inputs(input_vecs)\n",
    "        rnn_outputs = [s.output() for s in states]\n",
    "        return rnn_outputs\n",
    "    \n",
    "    def _get_probs(self, rnn_output):\n",
    "        output_w = dy.parameter(self.output_w)\n",
    "        output_b = dy.parameter(self.output_b)\n",
    "\n",
    "        probs = dy.softmax(output_w * rnn_output + output_b)\n",
    "        return probs\n",
    "    \n",
    "            \n",
    "    def get_loss(self, input_string, output_string):\n",
    "        input_string = self._add_eos(input_string)\n",
    "        output_string = self._add_eos(output_string)\n",
    "\n",
    "        dy.renew_cg()\n",
    "\n",
    "        probs = self(input_string)\n",
    "        loss = [-dy.log(dy.pick(p, output_char)) for p, output_char in zip(probs, output_string)]\n",
    "        loss = dy.esum(loss)\n",
    "        return loss\n",
    "\n",
    "    def _predict(self, probs):\n",
    "        probs = probs.value()\n",
    "        predicted_char = int2char[probs.index(max(probs))]\n",
    "        return predicted_char\n",
    "    \n",
    "    def generate(self, input_string):\n",
    "        input_string = self._add_eos(input_string)\n",
    "\n",
    "        dy.renew_cg()\n",
    "        \n",
    "        probs = self(input_string)\n",
    "        output_string = [self._predict(p) for p in probs]\n",
    "        output_string = ''.join(output_string)\n",
    "        return output_string.replace('<EOS>', '')\n",
    "    \n",
    "    def _attend(self, input_vectors, state):\n",
    "        w1 = dy.parameter(self.attention_w1)\n",
    "        w2 = dy.parameter(self.attention_w2)\n",
    "        v = dy.parameter(self.attention_v)\n",
    "        attention_weights = []\n",
    "\n",
    "        w2dt = w2 * state.h()[-1]\n",
    "        for input_vector in input_vectors:\n",
    "            attention_weight = v * dy.tanh(w1 * input_vector + w2dt)\n",
    "            attention_weights.append(attention_weight)\n",
    "        attention_weights = dy.softmax(dy.concatenate(attention_weights))\n",
    "\n",
    "        output_vectors = dy.esum(\n",
    "            [vector * attention_weight for vector, attention_weight in zip(input_vectors, attention_weights)])\n",
    "        return output_vectors\n",
    "    \n",
    "    def _encode_string(self, embedded_string):\n",
    "        initial_state = self.ENC_RNN.initial_state()\n",
    "        # run_rnn returns all the hidden state of all the slices of the RNN\n",
    "        hidden_states = self._run_rnn(initial_state, embedded_string)\n",
    "\n",
    "        return hidden_states\n",
    "    \n",
    "    def __call__(self, input_string):\n",
    "        dy.renew_cg()\n",
    "\n",
    "        embedded_string = self._embed_string(input_string)\n",
    "        encoded_string = self._encode_string(embedded_string)\n",
    "\n",
    "        rnn_state = self.DEC_RNN.initial_state().add_input(dy.vecInput(self.state_size))\n",
    "\n",
    "        probs = []\n",
    "        for _ in range(len(input_string)):\n",
    "            attended_encoding = self._attend(encoded_string, rnn_state)\n",
    "            rnn_state = rnn_state.add_input(attended_encoding)\n",
    "            p = self._get_probs(rnn_state.output())\n",
    "            probs.append(p)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     10,
     21
    ]
   },
   "outputs": [],
   "source": [
    "def _preprocess_string(strings):\n",
    "    batch_size = len(strings)\n",
    "\n",
    "    strings_with_eos = [list(string) + [EOS] for string in strings]\n",
    "    max_len = max([len(string) for string in strings_with_eos])\n",
    "    padded_strings = [string + [PAD] * (max_len - len(string)) for string in strings_with_eos]\n",
    "    int_strings = [[char2int[c] for c in string] for string in padded_strings]\n",
    "    var = Variable(torch.LongTensor(int_strings))\n",
    "    return var\n",
    "\n",
    "def get_loss(network, input_strings, output_strings):\n",
    "    batch_size = len(output_strings)\n",
    "    input_strings_t = _preprocess_string(input_strings)\n",
    "    output_strings_t = _preprocess_string(output_strings)\n",
    "\n",
    "    probs = network(input_strings_t, batch_size).permute(1, 0, 2)\n",
    "\n",
    "    loss = sum([F.cross_entropy(p, t, ignore_index=PAD_IDX) for p, t in zip(probs, output_strings_t)])\n",
    "\n",
    "    return loss\n",
    "\n",
    "def generate(network, input_string):\n",
    "    input_string = _preprocess_string([input_string])\n",
    "    probs = network(input_string, 1)\n",
    "    generated = [int2char[prob[0].topk(1)[1][0]] for prob in probs.data]\n",
    "    return (''.join(generated)).split(EOS)[0].replace(PAD, '')\n",
    "       \n",
    "def train(network, train_set, val_set, epochs=default_epochs):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        losses = [get_loss(network, [input_string], [output_string]).data[0]\n",
    "                 for input_string, output_string in val_set]\n",
    "        return sum(losses)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    optim = torch.optim.SGD(network.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for i, (input_string, output_string) in enumerate(tqdm(train_set)):\n",
    "              \n",
    "        optim.zero_grad()\n",
    "        loss = get_loss(network, [input_string], [output_string])\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "            \n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%int(len(train_set)/100) == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    #plt.axis([0, 100, 0, len(val_set)*MAX_STRING_LEN]])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPyTorch(nn.Module):\n",
    "    def __init__(self, embeddings_size, state_size):\n",
    "        super(AttentionPyTorch, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.embeddings = nn.Embedding(VOCAB_SIZE, embeddings_size, padding_idx=PAD_IDX)\n",
    "\n",
    "        self.enc = nn.LSTM(embeddings_size, state_size, 1)\n",
    "        self.dec = nn.LSTM(state_size, state_size, 1)\n",
    "\n",
    "        self.att_w1 = nn.Linear(state_size, state_size, bias=False)\n",
    "        self.att_w2 = nn.Linear(state_size, state_size, bias=False)\n",
    "        self.att_v = nn.Linear(state_size, 1, bias=False)\n",
    "\n",
    "        self.linear = nn.Linear(state_size, VOCAB_SIZE)\n",
    "\n",
    "    def get_rnn_init_state(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(1, batch_size, self.state_size))\n",
    "        c0 = Variable(torch.zeros(1, batch_size, self.state_size))\n",
    "        return h0, c0\n",
    "\n",
    "    def attend(self, encoder_outputs, decoder_state):\n",
    "        decoder_state = decoder_state[-1].unsqueeze(0)  # Use only the last layer\n",
    "        unnormalized_att = self.att_v(F.tanh(self.att_w1(decoder_state) + self.att_w2(encoder_outputs)))\n",
    "        # att = F.softmax(unnormalized_att)\n",
    "        att = F.softmax(unnormalized_att, dim=1)\n",
    "        attended = encoder_outputs.mul(att).sum(1)\n",
    "        return attended.unsqueeze(1)\n",
    "\n",
    "    def forward(self, input_string, batch_size):\n",
    "        # batch_size x seq_len\n",
    "        embedded = self.embeddings(input_string.transpose(1, 0))\n",
    "        # seq_len x batch_size x emb_size\n",
    "        encoder_outputs, hn = self.enc(embedded, self.get_rnn_init_state(batch_size))\n",
    "        # seq_len x  batch_size x state_size\n",
    "        hidden = self.get_rnn_init_state(batch_size)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.transpose(1, 0)\n",
    "        outputs = []\n",
    "        for _ in range(len(embedded)):\n",
    "            encoded = self.attend(encoder_outputs, hidden[0])\n",
    "            output, hidden = self.dec(encoded, hidden)\n",
    "            outputs.append(output)\n",
    "        logits = self.linear(torch.cat(outputs, 0))\n",
    "\n",
    "        return logits  # F.log_softmax(logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:03<00:00, 809.08it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDHRJKsT/B93pxTuACanFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b079780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on validation set: 0.0004056725629197899\n",
      "dcba\n"
     ]
    }
   ],
   "source": [
    "att_dynet = AttentionDyNet(EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train_dynet(att_dynet, train_set, val_set)\n",
    "print(att_dynet.generate('abcd'))\n",
    "#att_dynet.model.save('dynet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [12:16<00:00, 135.77it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb2aWMf8fPA0tji3ZjMIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10765bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on validation set: 0.0006459923297370551\n",
      "dcba\n"
     ]
    }
   ],
   "source": [
    "att_pytorch = AttentionPyTorch(EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train(att_pytorch, train_set, val_set)\n",
    "print(generate(att_pytorch, 'abcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
