{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyNet vs PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from random import choice, randrange\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "EOS = \"<EOS>\" #all strings will end with the End Of String token\n",
    "PAD = \"<PAD>\"\n",
    "characters = list(\"abcd\")\n",
    "characters.append(EOS)\n",
    "characters.append(PAD)\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "PAD_IDX = VOCAB_SIZE - 1\n",
    "\n",
    "def sample_model(min_length, max_lenth):\n",
    "    random_length = randrange(min_length, max_lenth)                             # Pick a random length\n",
    "    random_char_list = [choice(characters[:-2]) for _ in range(random_length)]  # Pick random chars\n",
    "    random_string = ''.join(random_char_list) \n",
    "    return random_string, random_string[::-1]  # Return the random string and its reverse\n",
    "    \n",
    "\n",
    "MIN_STRING_LEN = 1\n",
    "MAX_STRING_LEN = 10\n",
    "TRAIN_SET_SIZE = 5000\n",
    "VAL_SET_SIZE = 10\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 4\n",
    "STATE_SIZE = 64\n",
    "\n",
    "default_epochs = 20\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(TRAIN_SET_SIZE)]\n",
    "val_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(VAL_SET_SIZE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     10,
     21
    ]
   },
   "outputs": [],
   "source": [
    "def _preprocess_string(strings):\n",
    "    batch_size = len(strings)\n",
    "\n",
    "    strings_with_eos = [list(string) + [EOS] for string in strings]\n",
    "    max_len = max([len(string) for string in strings_with_eos])\n",
    "    padded_strings = [string + [PAD] * (max_len - len(string)) for string in strings_with_eos]\n",
    "    int_strings = [[char2int[c] for c in string] for string in padded_strings]\n",
    "    var = Variable(torch.LongTensor(int_strings))\n",
    "    return var\n",
    "\n",
    "def get_loss(network, input_strings, output_strings):\n",
    "    batch_size = len(output_strings)\n",
    "    input_strings_t = _preprocess_string(input_strings)\n",
    "    output_strings_t = _preprocess_string(output_strings)\n",
    "\n",
    "    probs = network(input_strings_t, batch_size).permute(1, 0, 2)\n",
    "\n",
    "    loss = sum([F.cross_entropy(p, t, ignore_index=PAD_IDX) for p, t in zip(probs, output_strings_t)])\n",
    "\n",
    "    return loss\n",
    "\n",
    "def generate(network, input_string):\n",
    "    input_string = _preprocess_string([input_string])\n",
    "    probs = network(input_string, 1)\n",
    "    generated = [int2char[prob[0].topk(1)[1][0]] for prob in probs.data]\n",
    "    return (''.join(generated)).split(EOS)[0].replace(PAD, '')\n",
    "       \n",
    "def train(network, train_set, val_set, epochs=default_epochs):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        losses = [get_loss(network, [input_string], [output_string]).data[0]\n",
    "                 for input_string, output_string in val_set]\n",
    "        return sum(losses)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    optim = torch.optim.SGD(network.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for i, (input_string, output_string) in enumerate(tqdm(train_set)):\n",
    "              \n",
    "        optim.zero_grad()\n",
    "        loss = get_loss(network, [input_string], [output_string])\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "            \n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%int(len(train_set)/100) == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    #plt.axis([0, 100, 0, len(val_set)*MAX_STRING_LEN]])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPyTorch(nn.Module):\n",
    "    def __init__(self, embeddings_size, state_size):\n",
    "        super(AttentionPyTorch, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.embeddings = nn.Embedding(VOCAB_SIZE, embeddings_size, padding_idx=PAD_IDX)\n",
    "\n",
    "        self.enc = nn.LSTM(embeddings_size, state_size, 1)\n",
    "        self.dec = nn.LSTM(state_size, state_size, 1)\n",
    "\n",
    "        self.att_w1 = nn.Linear(state_size, state_size, bias=False)\n",
    "        self.att_w2 = nn.Linear(state_size, state_size, bias=False)\n",
    "        self.att_v = nn.Linear(state_size, 1, bias=False)\n",
    "\n",
    "        self.linear = nn.Linear(state_size, VOCAB_SIZE)\n",
    "\n",
    "    def get_rnn_init_state(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(1, batch_size, self.state_size))\n",
    "        c0 = Variable(torch.zeros(1, batch_size, self.state_size))\n",
    "        return h0, c0\n",
    "\n",
    "    def attend(self, encoder_outputs, decoder_state):\n",
    "        decoder_state = decoder_state[-1].unsqueeze(0)  # Use only the last layer\n",
    "        unnormalized_att = self.att_v(F.tanh(self.att_w1(decoder_state) + self.att_w2(encoder_outputs)))\n",
    "        # att = F.softmax(unnormalized_att)\n",
    "        att = F.softmax(unnormalized_att, dim=1)\n",
    "        attended = encoder_outputs.mul(att).sum(1)\n",
    "        return attended.unsqueeze(1)\n",
    "\n",
    "    def forward(self, input_string, batch_size):\n",
    "        # batch_size x seq_len\n",
    "        embedded = self.embeddings(input_string.transpose(1, 0))\n",
    "        # seq_len x batch_size x emb_size\n",
    "        encoder_outputs, hn = self.enc(embedded, self.get_rnn_init_state(batch_size))\n",
    "        # seq_len x  batch_size x state_size\n",
    "        hidden = self.get_rnn_init_state(batch_size)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.transpose(1, 0)\n",
    "        outputs = []\n",
    "        for _ in range(len(embedded)):\n",
    "            encoded = self.attend(encoder_outputs, hidden[0])\n",
    "            output, hidden = self.dec(encoded, hidden)\n",
    "            outputs.append(output)\n",
    "        logits = self.linear(torch.cat(outputs, 0))\n",
    "\n",
    "        return logits  # F.log_softmax(logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [12:16<00:00, 135.77it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb2aWMf8fPA0tji3ZjMIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10765bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on validation set: 0.0006459923297370551\n",
      "dcba\n"
     ]
    }
   ],
   "source": [
    "att_pytorch = AttentionPyTorch(EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train(att_pytorch, train_set, val_set)\n",
    "print(generate(att_pytorch, 'abcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
