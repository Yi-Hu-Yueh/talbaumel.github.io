{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from random import choice, randrange\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "EOS = \"<EOS>\" #all strings will end with the End Of String token\n",
    "PAD = \"<PAD>\"\n",
    "characters = list(\"abcd\")\n",
    "characters.append(EOS)\n",
    "characters.append(PAD)\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "\n",
    "def sample_model(min_length, max_lenth):\n",
    "    random_length = randrange(min_length, max_lenth)                             # Pick a random length\n",
    "    random_char_list = [choice(characters[:-2]) for _ in range(random_length)]  # Pick random chars\n",
    "    random_string = ''.join(random_char_list) \n",
    "    return random_string, random_string[::-1]  # Return the random string and its reverse\n",
    "    \n",
    "\n",
    "MAX_STRING_LEN = 15\n",
    "batch_size = 100\n",
    "\n",
    "train_set = [sample_model(1, MAX_STRING_LEN) for _ in range(3000)]\n",
    "val_set = [sample_model(1, MAX_STRING_LEN) for _ in range(50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_string(strings):\n",
    "    strings_with_eos = [list(string) + [EOS] for string in strings]\n",
    "    max_len = max([len(string) for string in strings_with_eos])\n",
    "    padded_strings = [string+[PAD]*(max_len-len(string)) for string in strings_with_eos]\n",
    "    int_strings = [[char2int[c] for c in string] for string in padded_strings]\n",
    "    transposed = [[int_strings[j][i] for j in range(len(strings))] for i in range(max_len)]\n",
    "    return Variable(torch.LongTensor(transposed))\n",
    "\n",
    "def get_loss(network, input_strings, output_strings):\n",
    "    batch_size = len(output_strings)\n",
    "    input_strings = _preprocess_string(input_strings)\n",
    "    output_strings = _preprocess_string(output_strings)\n",
    "\n",
    "    probs = network(input_strings, batch_size)\n",
    "    \n",
    "    loss = sum([F.nll_loss(p, t) for p, t in zip(probs, output_strings)])\n",
    "    return loss\n",
    "\n",
    "def generate(network, input_string):\n",
    "    input_string = _preprocess_string([input_string])\n",
    "    probs = network(input_string, 1)\n",
    "    generated = [int2char[prob[0].topk(1)[1][0]] for prob in probs.data]\n",
    "    return (''.join(generated)).split(EOS)[0].replace(PAD, '')\n",
    "\n",
    "def batcher(dataset, epochs = 1):\n",
    "    sources, targets = [], []\n",
    "    i = 0\n",
    "    for _ in range(epochs):\n",
    "        for source, target in dataset:\n",
    "            i+=1\n",
    "            sources.append(source), targets.append(target)\n",
    "            if i%batch_size == 0:\n",
    "                yield sources, targets\n",
    "                sources, targets = [], []\n",
    "    if sources: yield sources, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, train_set, val_set, epochs = 30):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        losses = [get_loss(network, input_strings, output_strings).data[0]\n",
    "                 for input_strings, output_strings in batcher(val_set)]\n",
    "        return sum(losses)\n",
    "    \n",
    "    losses = []\n",
    "    iterations = []\n",
    "    optim = torch.optim.SGD(network.parameters(), lr = 0.05, momentum=0.9)\n",
    "    \n",
    "    for i, (input_strings, output_strings) in enumerate(tqdm(batcher(train_set, epochs=epochs))):\n",
    "              \n",
    "        optim.zero_grad()\n",
    "        loss = get_loss(network, input_strings, output_strings)\n",
    "        loss_value = loss.data[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "            \n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%100 == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    #plt.axis([0, 100, 0, 100])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class SimpleRNNNetwork(nn.Module):\n",
    "    def __init__(self,num_of_layers, embeddings_size, state_size):\n",
    "        super(SimpleRNNNetwork, self).__init__()\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        # the embedding paramaters\n",
    "        self.embeddings = nn.Embedding(VOCAB_SIZE, embeddings_size)\n",
    "\n",
    "        # the rnn\n",
    "        self.RNN = nn.LSTM(embeddings_size, state_size, num_of_layers)\n",
    "        \n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.linear = nn.Linear(state_size, VOCAB_SIZE)    \n",
    "        \n",
    "    def lstm_init_func(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        c0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        return h0,c0\n",
    "    \n",
    "    def __call__(self, input_string, batch_size):                        \n",
    "        embedded = self.embeddings(input_string)\n",
    "        output, hn = self.RNN(embedded, self.lstm_init_func(batch_size))\n",
    "        logits = self.linear(output)\n",
    "        return F.log_softmax(logits, 2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [00:33, 26.82it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a0d5128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on validation set: 9.447744369506836\n",
      "abb\n"
     ]
    }
   ],
   "source": [
    "RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 4\n",
    "STATE_SIZE = 128\n",
    "\n",
    "lstm_net = SimpleRNNNetwork(RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train(lstm_net, train_set, val_set)\n",
    "print(generate(lstm_net, 'abc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderNetwork(nn.Module):\n",
    "    def __init__(self, num_of_layers, embeddings_size, state_size):\n",
    "        super(EncoderDecoderNetwork, self).__init__()\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        self.embeddings = nn.Embedding(VOCAB_SIZE, embeddings_size)\n",
    "\n",
    "        self.enc = nn.LSTM(embeddings_size, state_size, num_of_layers)\n",
    "        self.dec = nn.LSTM(state_size, state_size, num_of_layers)\n",
    "        \n",
    "        self.linear = nn.Linear(state_size, VOCAB_SIZE)\n",
    "    \n",
    "    def get_rnn_init_state(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        c0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        return h0,c0\n",
    "    \n",
    "    def __call__(self, input_string, batch_size):\n",
    "        embedded = self.embeddings(input_string)\n",
    "        output, hn = self.enc(embedded, self.get_rnn_init_state(batch_size))\n",
    "        encoded = output[-1].unsqueeze(0)\n",
    "        hidden = self.get_rnn_init_state(batch_size)\n",
    "        outputs = []\n",
    "        for _ in range(len(input_string)):\n",
    "            output, hidden = self.dec(encoded, hidden)\n",
    "            outputs.append(output)\n",
    "        logits = self.linear(torch.torch.cat(outputs, 0))\n",
    "\n",
    "        return F.log_softmax(logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2320it [03:16, 11.82it/s]"
     ]
    }
   ],
   "source": [
    "encoder_decoder = EncoderDecoderNetwork(RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train(encoder_decoder, train_set, val_set, 100)\n",
    "print(generate(encoder_decoder, 'abcd'))\n",
    "print(generate(encoder_decoder, 'abcdabcdabcdabcd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderAttentionNetwork(nn.Module):\n",
    "    def __init__(self, num_of_layers, embeddings_size, state_size):\n",
    "        super(EncoderDecoderAttentionNetwork, self).__init__()\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.state_size = state_size\n",
    "        # the embedding paramaters\n",
    "        self.embeddings = nn.Embedding(VOCAB_SIZE, embeddings_size)\n",
    "\n",
    "        # the encoder\n",
    "        self.enc = nn.LSTM(embeddings_size, state_size, num_of_layers)\n",
    "\n",
    "        # the decoder\n",
    "        self.dec = nn.LSTM(state_size, state_size, num_of_layers)\n",
    "\n",
    "        # the attention\n",
    "        self.att_w1 = nn.Linear(state_size, state_size, bias=False)\n",
    "        self.att_w2 = nn.Linear(state_size, state_size)\n",
    "        self.att_v = nn.Linear(state_size, 1)\n",
    "\n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.linear = nn.Linear(state_size, VOCAB_SIZE)\n",
    "\n",
    "    def attention(self, encoder_outputs, decoder_state):\n",
    "        unnormalized_att = self.att_v(F.tanh(self.att_w1(decoder_state) + self.att_w2(encoder_outputs)))\n",
    "        att = F.softmax(unnormalized_att.permute(1,0,2), dim=1).permute(1,0,2)\n",
    "        attended = encoder_outputs.mul(att).sum(0)\n",
    "        return attended.unsqueeze(0)\n",
    "    \n",
    "    def get_rnn_init_state(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        c0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        return h0, c0\n",
    "    \n",
    "    def __call__(self, input_string, batch_size):\n",
    "        embedded = self.embeddings(input_string)\n",
    "        encoder_outputs, hn = self.enc(embedded, self.get_rnn_init_state(batch_size))\n",
    "\n",
    "        hiddens = self.get_rnn_init_state(batch_size)\n",
    "        outputs = []\n",
    "        for _ in range(len(input_string)):\n",
    "            encoded = self.attention(encoder_outputs, hiddens[0])\n",
    "            output, hiddens = self.dec(encoded, hiddens)\n",
    "            outputs.append(output)\n",
    "        logits = self.linear(torch.torch.cat(outputs, 0))\n",
    "\n",
    "        return F.log_softmax(logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = EncoderDecoderAttentionNetwork(\n",
    "    RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train(att, train_set, val_set)\n",
    "print(generate(att, 'abcdabcdabcdabcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
