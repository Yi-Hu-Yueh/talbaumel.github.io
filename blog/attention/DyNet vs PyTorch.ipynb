{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyNet vs PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from random import choice, randrange\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "EOS = \"<EOS>\" #all strings will end with the End Of String token\n",
    "PAD = \"<PAD>\"\n",
    "characters = list(\"abcd\")\n",
    "characters.append(EOS)\n",
    "characters.append(PAD)\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "PAD_IDX = VOCAB_SIZE - 1\n",
    "\n",
    "def sample_model(min_length, max_lenth):\n",
    "    random_length = randrange(min_length, max_lenth)                             # Pick a random length\n",
    "    random_char_list = [choice(characters[:-2]) for _ in range(random_length)]  # Pick random chars\n",
    "    random_string = ''.join(random_char_list) \n",
    "    return random_string, random_string[::-1]  # Return the random string and its reverse\n",
    "    \n",
    "\n",
    "MIN_STRING_LEN = 1\n",
    "MAX_STRING_LEN = 10\n",
    "TRAIN_SET_SIZE = 5000\n",
    "VAL_SET_SIZE = 10\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 4\n",
    "STATE_SIZE = 64\n",
    "\n",
    "default_epochs = 20\n",
    "\n",
    "train_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(TRAIN_SET_SIZE)]\n",
    "val_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(VAL_SET_SIZE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyNet Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import dynet as dy\n",
    "from tqdm import tqdm\n",
    "def train_dynet(network, train_set, val_set, epochs = default_epochs):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        loss = [network.get_loss(input_string, output_string).value() for input_string, output_string in val_set]\n",
    "        return sum(loss)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    trainer = dy.SimpleSGDTrainer(network.model)\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    for i, training_example in enumerate(tqdm(train_set)):\n",
    "        input_string, output_string = training_example\n",
    "        \n",
    "        loss = network.get_loss(input_string, output_string)\n",
    "        loss_value = loss.value()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "\n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%(len(train_set)/100) == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    plt.axis([0, 100, 0, len(val_set)*MAX_STRING_LEN])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "RNN_BUILDER = dy.LSTMBuilder\n",
    "    \n",
    "class AttentionDyNet():\n",
    "    def __init__(self, num_of_layers, embeddings_size, state_size):\n",
    "        self.model = dy.Model()\n",
    "\n",
    "        # the embedding paramaters\n",
    "        self.embeddings = self.model.add_lookup_parameters((VOCAB_SIZE, embeddings_size))\n",
    "\n",
    "        # the rnns\n",
    "        self.ENC_RNN = RNN_BUILDER(num_of_layers, embeddings_size, state_size, self.model)\n",
    "        self.DEC_RNN = RNN_BUILDER(num_of_layers, state_size, state_size, self.model)\n",
    "\n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.output_w = self.model.add_parameters((VOCAB_SIZE, state_size))\n",
    "        self.output_b = self.model.add_parameters((VOCAB_SIZE))\n",
    "\n",
    "        # attention weights\n",
    "        self.attention_w1 = self.model.add_parameters((state_size, state_size))\n",
    "        self.attention_w2 = self.model.add_parameters((state_size, state_size))\n",
    "        self.attention_v = self.model.add_parameters((1, state_size))\n",
    "\n",
    "        self.state_size = state_size\n",
    "        \n",
    "    def _add_eos(self, string):\n",
    "        string = list(string) + [EOS]\n",
    "        return [char2int[c] for c in string]\n",
    "    \n",
    "    def _embed_string(self, string):\n",
    "        return [self.embeddings[char] for char in string]\n",
    "\n",
    "    def _run_rnn(self, init_state, input_vecs):\n",
    "        s = init_state\n",
    "\n",
    "        states = s.add_inputs(input_vecs)\n",
    "        rnn_outputs = [s.output() for s in states]\n",
    "        return rnn_outputs\n",
    "    \n",
    "    def _get_probs(self, rnn_output):\n",
    "        output_w = dy.parameter(self.output_w)\n",
    "        output_b = dy.parameter(self.output_b)\n",
    "\n",
    "        probs = dy.softmax(output_w * rnn_output + output_b)\n",
    "        return probs\n",
    "    \n",
    "            \n",
    "    def get_loss(self, input_string, output_string):\n",
    "        input_string = self._add_eos(input_string)\n",
    "        output_string = self._add_eos(output_string)\n",
    "\n",
    "        dy.renew_cg()\n",
    "\n",
    "        probs = self(input_string)\n",
    "        loss = [-dy.log(dy.pick(p, output_char)) for p, output_char in zip(probs, output_string)]\n",
    "        loss = dy.esum(loss)\n",
    "        return loss\n",
    "\n",
    "    def _predict(self, probs):\n",
    "        probs = probs.value()\n",
    "        predicted_char = int2char[probs.index(max(probs))]\n",
    "        return predicted_char\n",
    "    \n",
    "    def generate(self, input_string):\n",
    "        input_string = self._add_eos(input_string)\n",
    "\n",
    "        dy.renew_cg()\n",
    "        \n",
    "        probs = self(input_string)\n",
    "        output_string = [self._predict(p) for p in probs]\n",
    "        output_string = ''.join(output_string)\n",
    "        return output_string.replace('<EOS>', '')\n",
    "    \n",
    "    def _attend(self, input_vectors, state):\n",
    "        w1 = dy.parameter(self.attention_w1)\n",
    "        w2 = dy.parameter(self.attention_w2)\n",
    "        v = dy.parameter(self.attention_v)\n",
    "        attention_weights = []\n",
    "\n",
    "        w2dt = w2 * state.h()[-1]\n",
    "        for input_vector in input_vectors:\n",
    "            attention_weight = v * dy.tanh(w1 * input_vector + w2dt)\n",
    "            attention_weights.append(attention_weight)\n",
    "        attention_weights = dy.softmax(dy.concatenate(attention_weights))\n",
    "\n",
    "        output_vectors = dy.esum(\n",
    "            [vector * attention_weight for vector, attention_weight in zip(input_vectors, attention_weights)])\n",
    "        return output_vectors\n",
    "    \n",
    "    def _encode_string(self, embedded_string):\n",
    "        initial_state = self.ENC_RNN.initial_state()\n",
    "        # run_rnn returns all the hidden state of all the slices of the RNN\n",
    "        hidden_states = self._run_rnn(initial_state, embedded_string)\n",
    "\n",
    "        return hidden_states\n",
    "    \n",
    "    def __call__(self, input_string):\n",
    "        dy.renew_cg()\n",
    "\n",
    "        embedded_string = self._embed_string(input_string)\n",
    "        encoded_string = self._encode_string(embedded_string)\n",
    "\n",
    "        rnn_state = self.DEC_RNN.initial_state().add_input(dy.vecInput(self.state_size))\n",
    "\n",
    "        probs = []\n",
    "        for _ in range(len(input_string)):\n",
    "            attended_encoding = self._attend(encoded_string, rnn_state)\n",
    "            rnn_state = rnn_state.add_input(attended_encoding)\n",
    "            p = self._get_probs(rnn_state.output())\n",
    "            probs.append(p)\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_string(strings):\n",
    "    batch_size = len(strings)\n",
    "\n",
    "    strings_with_eos = [list(string) + [EOS] for string in strings]\n",
    "    max_len = max([len(string) for string in strings_with_eos])\n",
    "    padded_strings = [string + [PAD] * (max_len - len(string)) for string in strings_with_eos]\n",
    "    #len_first = [[padded_strings[j][i]for j in range(batch_size)] for i in range(max_len)]\n",
    "    #int_strings = [[char2int[c] for c in string] for string in len_first]\n",
    "    int_strings = [[char2int[c] for c in string] for string in padded_strings]\n",
    "    var = Variable(torch.LongTensor(int_strings))\n",
    "    return var\n",
    "\n",
    "def get_loss(network, input_strings, output_strings):\n",
    "    batch_size = len(output_strings)\n",
    "    input_strings_t = _preprocess_string(input_strings)\n",
    "    output_strings_t = _preprocess_string(output_strings)\n",
    "\n",
    "    probs = network(input_strings_t, batch_size).permute(1, 0, 2)\n",
    "\n",
    "    loss = sum([F.cross_entropy(p, t, ignore_index=PAD_IDX) for p, t in zip(probs, output_strings_t)])\n",
    "    #loss = F.cross_entropy(probs.unsqueeze(0) , output_strings_t, ignore_index=PAD_IDX, size_average=False) \n",
    "\n",
    "    return loss\n",
    "\n",
    "def generate(network, input_string):\n",
    "    input_string = _preprocess_string([input_string])\n",
    "    probs = network(input_string, 1)\n",
    "    generated = [int2char[prob[0].topk(1)[1][0]] for prob in probs.data]\n",
    "    return (''.join(generated)).split(EOS)[0].replace(PAD, '')\n",
    "\n",
    "def batcher(dataset, epochs = 1):\n",
    "    sources, targets = [], []\n",
    "    i = 0\n",
    "    for _ in range(epochs):\n",
    "        for source, target in dataset:\n",
    "            i+=1\n",
    "            sources.append(source), targets.append(target)\n",
    "            if len(sources) >= batch_size:\n",
    "                yield sources, targets\n",
    "                sources, targets = [], []\n",
    "    if sources: yield sources, targets\n",
    "        \n",
    "def train(network, train_set, val_set, epochs=default_epochs):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        losses = [get_loss(network, input_strings, output_strings).data[0]\n",
    "                 for input_strings, output_strings in batcher(val_set)]\n",
    "        return sum(losses)\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    optim = torch.optim.SGD(network.parameters(), lr = 0.1)\n",
    "    \n",
    "    total_iterations = max(int((len(train_set)*epochs)/batch_size), 100)\n",
    "    for i, (input_strings, output_strings) in enumerate(tqdm(batcher(train_set, epochs=epochs))):\n",
    "              \n",
    "        optim.zero_grad()\n",
    "        loss = get_loss(network, input_strings, output_strings)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "            \n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%int(total_iterations/100) == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    plt.axis([0, 100, 0, 100])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPyTorch(nn.Module):\n",
    "    def __init__(self, num_of_layers, embeddings_size, state_size):\n",
    "        super(AttentionPyTorch, self).__init__()\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        self.embeddings = nn.Embedding(VOCAB_SIZE, embeddings_size, padding_idx=PAD_IDX)\n",
    "\n",
    "        self.enc = nn.LSTM(embeddings_size, state_size, num_of_layers)\n",
    "        self.dec = nn.LSTM(state_size, state_size, num_of_layers)\n",
    "        \n",
    "        self.linear = nn.Linear(state_size, VOCAB_SIZE)\n",
    "        # the attention\n",
    "        self.att_w1 = nn.Linear(state_size, state_size, bias=False)\n",
    "        self.att_w2 = nn.Linear(state_size, state_size)\n",
    "        self.att_v = nn.Linear(state_size, 1)\n",
    "    \n",
    "    def get_rnn_init_state(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        c0 = Variable(torch.zeros(self.num_of_layers, batch_size, self.state_size))\n",
    "        return h0, c0\n",
    "    \n",
    "    def encode(self, encoder_outputs, decoder_state):\n",
    "        decoder_state = decoder_state[-1].unsqueeze(0) # Use only the last layer\n",
    "        unnormalized_att = self.att_v(F.tanh(self.att_w1(decoder_state) + self.att_w2(encoder_outputs)))\n",
    "        #att = F.softmax(unnormalized_att)\n",
    "        att = F.softmax(unnormalized_att.permute(1,0,2), dim=1).permute(1,0,2)\n",
    "        attended = encoder_outputs.mul(att).sum(0)\n",
    "        return attended.unsqueeze(0)\n",
    "    \n",
    "    def forward(self, input_string, batch_size):\n",
    "        embedded = self.embeddings(input_string.permute(1, 0))\n",
    "        encoder_outputs, hn = self.enc(embedded, self.get_rnn_init_state(batch_size))\n",
    "        \n",
    "        hidden = self.get_rnn_init_state(batch_size)\n",
    "        \n",
    "        outputs = []\n",
    "        for _ in range(len(embedded)):\n",
    "            encoded = self.encode(encoder_outputs, hidden[0])\n",
    "            output, hidden = self.dec(encoded, hidden)\n",
    "            outputs.append(output)\n",
    "        logits = self.linear(torch.cat(outputs, 0))\n",
    "\n",
    "        return logits #F.log_softmax(logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 4\n",
    "STATE_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:17<00:00, 1288.35it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b56e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on validation set: 0.0005570704197452869\n",
      "bbdcbadcbacbcb\n"
     ]
    }
   ],
   "source": [
    "att_dynet = AttentionDyNet(NUM_OF_LAYERS, EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train_dynet(att_dynet, train_set, val_set)\n",
    "print(att_dynet.generate('abcdabcdabcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [11:02, 151.05it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nof4/5F2bbJdSf90AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b56828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on validation set: 0.0008133606133924332\n",
      "dddcbadcba\n"
     ]
    }
   ],
   "source": [
    "att_pytorch = AttentionPyTorch(RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train(att_pytorch, train_set, val_set)\n",
    "print(generate(att_pytorch, 'abcdabcdabcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
