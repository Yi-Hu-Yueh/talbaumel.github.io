{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyNet vs PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from random import choice, randrange\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "EOS = \"<EOS>\" #all strings will end with the End Of String token\n",
    "PAD = \"<PAD>\"\n",
    "characters = list(\"abcd\")\n",
    "characters.append(EOS)\n",
    "characters.append(PAD)\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "PAD_IDX = VOCAB_SIZE - 1\n",
    "\n",
    "def sample_model(min_length, max_lenth):\n",
    "    random_length = randrange(min_length, max_lenth)                             # Pick a random length\n",
    "    random_char_list = [choice(characters[:-2]) for _ in range(random_length)]  # Pick random chars\n",
    "    random_string = ''.join(random_char_list) \n",
    "    return random_string, random_string[::-1]  # Return the random string and its reverse\n",
    "    \n",
    "\n",
    "MIN_STRING_LEN = 1\n",
    "MAX_STRING_LEN = 10\n",
    "TRAIN_SET_SIZE = 5000\n",
    "VAL_SET_SIZE = 10\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 4\n",
    "STATE_SIZE = 64\n",
    "\n",
    "default_epochs = 20\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(TRAIN_SET_SIZE)]\n",
    "val_set = [sample_model(MIN_STRING_LEN, MAX_STRING_LEN) for _ in range(VAL_SET_SIZE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyNet Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import dynet as dy\n",
    "from tqdm import tqdm\n",
    "def train_dynet(network, train_set, val_set, epochs = default_epochs):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        loss = [network.get_loss(input_string, output_string).value() for input_string, output_string in val_set]\n",
    "        return sum(loss)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    trainer = dy.SimpleSGDTrainer(network.model, learning_rate=learning_rate)\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    for i, training_example in enumerate(tqdm(train_set)):\n",
    "        input_string, output_string = training_example\n",
    "        \n",
    "        loss = network.get_loss(input_string, output_string)\n",
    "        loss_value = loss.value()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "\n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%(len(train_set)/100) == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    #plt.axis([0, 100, 0, len(val_set)*MAX_STRING_LEN])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class AttentionDyNet():\n",
    "    def __init__(self, embeddings_size, state_size):\n",
    "        self.model = dy.ParameterCollection()\n",
    "\n",
    "        # the embedding paramaters\n",
    "        self.embeddings = self.model.add_lookup_parameters((VOCAB_SIZE, embeddings_size))\n",
    "\n",
    "        # the rnns\n",
    "        self.ENC_RNN = dy.LSTMBuilder(1, embeddings_size, state_size, self.model)\n",
    "        self.DEC_RNN = dy.LSTMBuilder(1, state_size, state_size, self.model)\n",
    "\n",
    "        # project the rnn output to a vector of VOCAB_SIZE length\n",
    "        self.output_w = self.model.add_parameters((VOCAB_SIZE, state_size))\n",
    "        self.output_b = self.model.add_parameters((VOCAB_SIZE))\n",
    "\n",
    "        # attention weights\n",
    "        self.attention_w1 = self.model.add_parameters((state_size, state_size))\n",
    "        self.attention_w2 = self.model.add_parameters((state_size, state_size))\n",
    "        self.attention_v = self.model.add_parameters((1, state_size))\n",
    "\n",
    "        self.state_size = state_size\n",
    "        \n",
    "    def _add_eos(self, string):\n",
    "        string = list(string) + [EOS]\n",
    "        return [char2int[c] for c in string]\n",
    "    \n",
    "    def _embed_string(self, string):\n",
    "        return [self.embeddings[char] for char in string]\n",
    "\n",
    "    def _run_rnn(self, init_state, input_vecs):\n",
    "        s = init_state\n",
    "\n",
    "        states = s.add_inputs(input_vecs)\n",
    "        rnn_outputs = [s.output() for s in states]\n",
    "        return rnn_outputs\n",
    "    \n",
    "    def _get_probs(self, rnn_output):\n",
    "        output_w = dy.parameter(self.output_w)\n",
    "        output_b = dy.parameter(self.output_b)\n",
    "\n",
    "        probs = dy.softmax(output_w * rnn_output + output_b)\n",
    "        return probs\n",
    "    \n",
    "            \n",
    "    def get_loss(self, input_string, output_string):\n",
    "        input_string = self._add_eos(input_string)\n",
    "        output_string = self._add_eos(output_string)\n",
    "\n",
    "        dy.renew_cg()\n",
    "\n",
    "        probs = self(input_string)\n",
    "        loss = [-dy.log(dy.pick(p, output_char)) for p, output_char in zip(probs, output_string)]\n",
    "        loss = dy.esum(loss)\n",
    "        return loss\n",
    "\n",
    "    def _predict(self, probs):\n",
    "        probs = probs.value()\n",
    "        predicted_char = int2char[probs.index(max(probs))]\n",
    "        return predicted_char\n",
    "    \n",
    "    def generate(self, input_string):\n",
    "        input_string = self._add_eos(input_string)\n",
    "\n",
    "        dy.renew_cg()\n",
    "        \n",
    "        probs = self(input_string)\n",
    "        output_string = [self._predict(p) for p in probs]\n",
    "        output_string = ''.join(output_string)\n",
    "        return output_string.replace('<EOS>', '')\n",
    "    \n",
    "    def _attend(self, input_vectors, state):\n",
    "        w1 = dy.parameter(self.attention_w1)\n",
    "        w2 = dy.parameter(self.attention_w2)\n",
    "        v = dy.parameter(self.attention_v)\n",
    "        attention_weights = []\n",
    "\n",
    "        w2dt = w2 * state.h()[-1]\n",
    "        for input_vector in input_vectors:\n",
    "            attention_weight = v * dy.tanh(w1 * input_vector + w2dt)\n",
    "            attention_weights.append(attention_weight)\n",
    "        attention_weights = dy.softmax(dy.concatenate(attention_weights))\n",
    "\n",
    "        output_vectors = dy.esum(\n",
    "            [vector * attention_weight for vector, attention_weight in zip(input_vectors, attention_weights)])\n",
    "        return output_vectors\n",
    "    \n",
    "    def _encode_string(self, embedded_string):\n",
    "        initial_state = self.ENC_RNN.initial_state()\n",
    "        # run_rnn returns all the hidden state of all the slices of the RNN\n",
    "        hidden_states = self._run_rnn(initial_state, embedded_string)\n",
    "\n",
    "        return hidden_states\n",
    "    \n",
    "    def __call__(self, input_string):\n",
    "        dy.renew_cg()\n",
    "\n",
    "        embedded_string = self._embed_string(input_string)\n",
    "        encoded_string = self._encode_string(embedded_string)\n",
    "\n",
    "        rnn_state = self.DEC_RNN.initial_state().add_input(dy.vecInput(self.state_size))\n",
    "\n",
    "        probs = []\n",
    "        for _ in range(len(input_string)):\n",
    "            attended_encoding = self._attend(encoded_string, rnn_state)\n",
    "            rnn_state = rnn_state.add_input(attended_encoding)\n",
    "            p = self._get_probs(rnn_state.output())\n",
    "            probs.append(p)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     10,
     21
    ]
   },
   "outputs": [],
   "source": [
    "def _preprocess_string(strings):\n",
    "    batch_size = len(strings)\n",
    "\n",
    "    strings_with_eos = [list(string) + [EOS] for string in strings]\n",
    "    max_len = max([len(string) for string in strings_with_eos])\n",
    "    padded_strings = [string + [PAD] * (max_len - len(string)) for string in strings_with_eos]\n",
    "    int_strings = [[char2int[c] for c in string] for string in padded_strings]\n",
    "    var = Variable(torch.LongTensor(int_strings))\n",
    "    return var\n",
    "\n",
    "def get_loss(network, input_strings, output_strings):\n",
    "    batch_size = len(output_strings)\n",
    "    input_strings_t = _preprocess_string(input_strings)\n",
    "    output_strings_t = _preprocess_string(output_strings)\n",
    "\n",
    "    probs = network(input_strings_t, batch_size).permute(1, 0, 2)\n",
    "\n",
    "    loss = sum([F.cross_entropy(p, t, ignore_index=PAD_IDX) for p, t in zip(probs, output_strings_t)])\n",
    "\n",
    "    return loss\n",
    "\n",
    "def generate(network, input_string):\n",
    "    input_string = _preprocess_string([input_string])\n",
    "    probs = network(input_string, 1)\n",
    "    generated = [int2char[prob[0].topk(1)[1][0]] for prob in probs.data]\n",
    "    return (''.join(generated)).split(EOS)[0].replace(PAD, '')\n",
    "       \n",
    "def train(network, train_set, val_set, epochs=default_epochs):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        losses = [get_loss(network, [input_string], [output_string]).data[0]\n",
    "                 for input_string, output_string in val_set]\n",
    "        return sum(losses)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    losses = []\n",
    "    iterations = []\n",
    "    optim = torch.optim.SGD(network.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for i, (input_string, output_string) in enumerate(tqdm(train_set)):\n",
    "              \n",
    "        optim.zero_grad()\n",
    "        loss = get_loss(network, [input_string], [output_string])\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "            \n",
    "        # Accumulate average losses over training to plot\n",
    "        if i%int(len(train_set)/100) == 0:\n",
    "            val_loss = get_val_set_loss(network, val_set)\n",
    "            losses.append(val_loss)\n",
    "            iterations.append(i/((len(train_set)/100)))\n",
    "\n",
    "    plt.plot(iterations, losses)\n",
    "    #plt.axis([0, 100, 0, len(val_set)*MAX_STRING_LEN]])\n",
    "    plt.show() \n",
    "    print('loss on validation set:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPyTorch(nn.Module):\n",
    "    def __init__(self, embeddings_size, state_size):\n",
    "        super(AttentionPyTorch, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.embeddings = nn.Embedding(VOCAB_SIZE, embeddings_size, padding_idx=PAD_IDX)\n",
    "\n",
    "        self.enc = nn.LSTM(embeddings_size, state_size, 1)\n",
    "        self.dec = nn.LSTM(state_size, state_size, 1)\n",
    "\n",
    "        self.att_w1 = nn.Linear(state_size, state_size, bias=False)\n",
    "        self.att_w2 = nn.Linear(state_size, state_size, bias=False)\n",
    "        self.att_v = nn.Linear(state_size, 1, bias=False)\n",
    "\n",
    "        self.linear = nn.Linear(state_size, VOCAB_SIZE)\n",
    "\n",
    "    def get_rnn_init_state(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(1, batch_size, self.state_size))\n",
    "        c0 = Variable(torch.zeros(1, batch_size, self.state_size))\n",
    "        return h0, c0\n",
    "\n",
    "    def attend(self, encoder_outputs, decoder_state):\n",
    "        decoder_state = decoder_state[-1].unsqueeze(0)  # Use only the last layer\n",
    "        unnormalized_att = self.att_v(F.tanh(self.att_w1(decoder_state) + self.att_w2(encoder_outputs)))\n",
    "        # att = F.softmax(unnormalized_att)\n",
    "        att = F.softmax(unnormalized_att, dim=1)\n",
    "        attended = encoder_outputs.mul(att).sum(1)\n",
    "        return attended.unsqueeze(1)\n",
    "\n",
    "    def forward(self, input_string, batch_size):\n",
    "        # batch_size x seq_len\n",
    "        embedded = self.embeddings(input_string.transpose(1, 0))\n",
    "        # seq_len x batch_size x emb_size\n",
    "        encoder_outputs, hn = self.enc(embedded, self.get_rnn_init_state(batch_size))\n",
    "        # seq_len x  batch_size x state_size\n",
    "        hidden = self.get_rnn_init_state(batch_size)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.transpose(1, 0)\n",
    "        outputs = []\n",
    "        for _ in range(len(embedded)):\n",
    "            encoded = self.attend(encoder_outputs, hidden[0])\n",
    "            output, hidden = self.dec(encoded, hidden)\n",
    "            outputs.append(output)\n",
    "        logits = self.linear(torch.cat(outputs, 0))\n",
    "\n",
    "        return logits  # F.log_softmax(logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:03<00:00, 809.08it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDHRJKsT/B93pxTuACanFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b079780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on validation set: 0.0004056725629197899\n",
      "dcba\n"
     ]
    }
   ],
   "source": [
    "att_dynet = AttentionDyNet(EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train_dynet(att_dynet, train_set, val_set)\n",
    "print(att_dynet.generate('abcd'))\n",
    "#att_dynet.model.save('dynet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62062/100000 [07:42<04:43, 134.04it/s]"
     ]
    }
   ],
   "source": [
    "att_pytorch = AttentionPyTorch(EMBEDDINGS_SIZE, STATE_SIZE)\n",
    "train(att_pytorch, train_set, val_set)\n",
    "print(generate(att_pytorch, 'abcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
