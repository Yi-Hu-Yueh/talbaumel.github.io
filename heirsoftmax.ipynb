{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling-Up Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are familiar with sequence to sequence models let’s discuss  how to scale them to real world problems. In the previous example we used a very small vocabulary (4 symbols $“a,b,c,d”$)  but when dealing with tasks such as automatic machine translation our vocabulary can contain thousands of unique words, that means that the last layer of our network must be the dimension as the size of the vocabulary and $softmax$ must be applied on an extremely long vector. When training a network we cannot afford such a costly operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's why hierarchical softmax was invented, it can increase softmax time by up to $log(n)$ without adding compromising too much of the network reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax function, or normalized exponential is used to transform a $n$ dimensional vector into a probabilty over $n$ classes, formaly it is defined as: $P(class=i | x) = \\dfrac{e^{x_i}}{\\sum_{j=1}^ne^{x_j}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy code for SoftMax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the softmax we need to $O(n)$ time. Let's see how can we reduce it to $O(log(n))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hierarchical Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hierarchical softmax function first arranges the output vocabulary in an hierarchical tree (we will discuss later how this tree can be constructed). Once we constructed the tree we can use softmax to select each branch of the tree. For example, given the following hierarchy and the value of the last hidden layer is $V$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/HierSoftMax.jpg\" width=\"25%\" height=\"25%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilty of the network to predict \"D\" is (the probabilty of choosing the 2nd branch in $B_1$)*(the provavilty of choosing the 1st branch on $B_3$). More formally:  $P(class=D | V) = softmax(V \\times W_{B_1})_1*softmax(V \\times W_{B_3})_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what is hierarchical softmax we can start implementing it. We will create an hier_softmax that will recieve an output hierarchy and will be able to calculate of the probabilty of an output given $V$ and to generate to most likely output given a vector $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will define some auxiliary functions to handle trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from copy import copy\n",
    "\n",
    "def _get_subtrees(tree):\n",
    "    yield tree\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == list:\n",
    "            for x in _get_subtrees(subtree):\n",
    "                yield x\n",
    "\n",
    "\n",
    "# Returns pairs of paths and leafves of a tree\n",
    "def _get_leaves_paths(tree):\n",
    "    for i, subtree in enumerate(tree):\n",
    "        if type(subtree) == list:\n",
    "            for path, value in _get_leaves_paths(subtree):\n",
    "                yield [i] + path, value\n",
    "        else:\n",
    "            yield [i], subtree\n",
    "\n",
    "\n",
    "# Returns the number of nodes in a tree (not including root)\n",
    "def _count_nodes(tree):\n",
    "    size = 0\n",
    "    for node in tree:\n",
    "        if type(node) == list:\n",
    "            size += 1 + _count_nodes(node)\n",
    "    return size\n",
    "\n",
    "\n",
    "# Returns all the nodes in a path\n",
    "def _get_nodes(tree, path):\n",
    "    next_node = 0\n",
    "    nodes = []\n",
    "    for decision in path:\n",
    "        nodes.append(next_node)\n",
    "        next_node += 1 + _count_nodes(tree[:decision])\n",
    "        tree = tree[decision]\n",
    "    return nodes\n",
    "\n",
    "\n",
    "# turns a list to a binary tree\n",
    "def random_binary_full_tree(outputs):\n",
    "    outputs = copy(outputs)\n",
    "    shuffle(outputs)\n",
    "\n",
    "    while len(outputs) > 2:\n",
    "        temp_outputs = []\n",
    "        for i in range(0, len(outputs), 2):\n",
    "            if len(outputs) - (i+1) > 0:\n",
    "                temp_outputs.append([outputs[i], outputs[i+1]])\n",
    "            else:\n",
    "                temp_outputs.append(outputs[i])\n",
    "        outputs = temp_outputs\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the auxiliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tree: [[[[7, 8], [6, 5]], [[4, 1], [0, 2]]], [9, 3]]\n",
      "All subtrees:\n",
      "\t[[[[7, 8], [6, 5]], [[4, 1], [0, 2]]], [9, 3]]\n",
      "\t[[[7, 8], [6, 5]], [[4, 1], [0, 2]]]\n",
      "\t[[7, 8], [6, 5]]\n",
      "\t[7, 8]\n",
      "\t[6, 5]\n",
      "\t[[4, 1], [0, 2]]\n",
      "\t[4, 1]\n",
      "\t[0, 2]\n",
      "\t[9, 3]\n",
      "All paths and leaves:\n",
      "\t([0, 0, 0, 0], 7)\n",
      "\t([0, 0, 0, 1], 8)\n",
      "\t([0, 0, 1, 0], 6)\n",
      "\t([0, 0, 1, 1], 5)\n",
      "\t([0, 1, 0, 0], 4)\n",
      "\t([0, 1, 0, 1], 1)\n",
      "\t([0, 1, 1, 0], 0)\n",
      "\t([0, 1, 1, 1], 2)\n",
      "\t([1, 0], 9)\n",
      "\t([1, 1], 3)\n",
      "Number of nodes in the tree: 8\n",
      "all nodes in path [0, 0, 0, 0]:\n",
      "\t0\n",
      "\t1\n",
      "\t2\n",
      "\t3\n"
     ]
    }
   ],
   "source": [
    "tree = random_binary_full_tree(range(10))\n",
    "print 'Our tree:',tree\n",
    "\n",
    "print 'All subtrees:'\n",
    "for subtree in _get_subtrees(tree):\n",
    "    print '\\t',subtree\n",
    "\n",
    "print 'All paths and leaves:'\n",
    "for subtree in _get_leaves_paths(tree):\n",
    "    print '\\t',subtree\n",
    "    \n",
    "print 'Number of nodes in the tree:',_count_nodes(tree)\n",
    "\n",
    "print 'all nodes in path [0, 0, 0, 0]:'\n",
    "for nodes in _get_nodes(tree, [0, 0, 0, 0]):\n",
    "    print '\\t',nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hier softmax class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycnn as pc\n",
    "\n",
    "class hier_softmax:\n",
    "    def __init__(self, tree, contex_size, model):\n",
    "        #create a weight matrix and bias vector for each node in the tree\n",
    "        for i, subtree in enumerate(_get_subtrees(tree)):\n",
    "            model.add_parameters(\"softmax_node_\"+str(i)+\"_w\", (len(subtree), contex_size))\n",
    "            model.add_parameters(\"softmax_node_\" + str(i) + \"_b\", len(subtree))\n",
    "        \n",
    "        #create a dictionary from each value to its path\n",
    "        value_to_path_and_nodes_dict = {}\n",
    "        for path, value in _get_leaves_paths(tree):\n",
    "            nodes = _get_nodes(tree, path)\n",
    "            value_to_path_and_nodes_dict[char2int[value]] = path, nodes\n",
    "        self.value_to_path_and_nodes_dict = value_to_path_and_nodes_dict\n",
    "        self.model = model\n",
    "        self.tree = tree\n",
    "    \n",
    "    #get the loss on a given value (for training)\n",
    "    def get_loss(self, context, value):\n",
    "        loss = []\n",
    "        path, nodes = self.value_to_path_and_nodes_dict[value]\n",
    "        for p, n in zip(path, nodes):\n",
    "            w = pc.parameter(self.model[\"softmax_node_\"+str(n)+\"_w\"])\n",
    "            b = pc.parameter(self.model[\"softmax_node_\" + str(n) + \"_b\"])\n",
    "            probs = pc.softmax(w*context+b)\n",
    "            loss.append(-pc.log(pc.pick(probs, p)))\n",
    "        return pc.esum(loss)\n",
    "\n",
    "    #get the most likely\n",
    "    def generate(self, context):\n",
    "        best_value = None\n",
    "        best_loss = float(100000)\n",
    "        for value in self.value_to_path_and_nodes_dict:\n",
    "            loss = self.get_loss(context, value)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_value = value\n",
    "        return best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the performance improvement we can get from the hier_softmax. Again, we will learn the reverse function, but this time on a big vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('684 437 885 280', '280 885 437 684')\n"
     ]
    }
   ],
   "source": [
    "from random import choice, randrange\n",
    "\n",
    "EOS = \"<EOS>\" #all strings will end with the End Of String token\n",
    "characters = [str(i) for i in range(1000)]\n",
    "characters.append(EOS)\n",
    "\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "\n",
    "VOCAB_SIZE = len(characters)\n",
    "\n",
    "def sample_model(min_length, max_lenth):\n",
    "    random_length = randrange(min_length, max_lenth)                             # Pick a random length\n",
    "    random_char_list = [choice(characters[:-1]) for _ in xrange(random_length)]  # Pick random chars\n",
    "    random_string = ' '.join(random_char_list)\n",
    "    reverse_string = ' '.join(random_char_list[::-1])\n",
    "    return random_string, reverse_string  # Return the random string and its reverse\n",
    "\n",
    "print sample_model(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "MAX_STRING_LEN = 5\n",
    "\n",
    "train_set = [sample_model(1, MAX_STRING_LEN) for _ in xrange(3000)]\n",
    "val_set = [sample_model(1, MAX_STRING_LEN) for _ in xrange(50)]\n",
    "\n",
    "def train(network, train_set, val_set, epochs = 20):\n",
    "    def get_val_set_loss(network, val_set):\n",
    "        loss = [network.get_loss(input_string, output_string).value() for input_string, output_string in val_set]\n",
    "        return sum(loss)\n",
    "    \n",
    "    train_set = train_set*epochs\n",
    "    trainer = pc.SimpleSGDTrainer(network.model)\n",
    "    start = datetime.now()\n",
    "    for i, training_example in enumerate(train_set):\n",
    "        input_string, output_string = training_example\n",
    "        \n",
    "        loss = network.get_loss(input_string, output_string)\n",
    "        loss_value = loss.value()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "    print datetime.now()-start\n",
    "        \n",
    "\n",
    "    print 'loss on validation set:', get_val_set_loss(network, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a large vocab data we can measure the training time of the attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import AttentionNetwork\n",
    "\n",
    "ENC_RNN_NUM_OF_LAYERS = 1\n",
    "DEC_RNN_NUM_OF_LAYERS = 1\n",
    "EMBEDDINGS_SIZE = 200\n",
    "ENC_STATE_SIZE = 210\n",
    "DEC_STATE_SIZE = 210\n",
    "\n",
    "att = AttentionNetwork(ENC_RNN_NUM_OF_LAYERS, DEC_RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, ENC_STATE_SIZE, DEC_STATE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:08:33.284177\n",
      "loss on validation set: 3.17660824512\n"
     ]
    }
   ],
   "source": [
    "train(att, train_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_tree = random_binary_full_tree(characters)\n",
    "\n",
    "\n",
    "RNN_BUILDER = pc.LSTMBuilder\n",
    "class AttentionNetworkWithHierSoftmax(AttentionNetwork):\n",
    "    def __init__(self, enc_layers, dec_layers, embeddings_size, enc_state_size, dec_state_size, tree):\n",
    "        self.model = pc.Model()\n",
    "\n",
    "        # the embedding paramaters\n",
    "        self.model.add_lookup_parameters(\"lookup\", (VOCAB_SIZE, embeddings_size))\n",
    "\n",
    "        # the rnns\n",
    "        self.ENC_RNN = RNN_BUILDER(enc_layers, embeddings_size, enc_state_size, self.model)\n",
    "        self.DEC_RNN = RNN_BUILDER(dec_layers, enc_state_size, dec_state_size, self.model)\n",
    "        \n",
    "        # attention weights\n",
    "        self.model.add_parameters(\"attention_w1\", (enc_state_size, enc_state_size))\n",
    "        self.model.add_parameters(\"attention_w2\", (enc_state_size, dec_state_size))\n",
    "        self.model.add_parameters(\"attention_v\", (1, enc_state_size))\n",
    "\n",
    "        self.enc_state_size = enc_state_size\n",
    "        \n",
    "        self.tree = tree\n",
    "        self.hier_softmax = hier_softmax(tree, dec_state_size, self.model)\n",
    "    \n",
    "    def get_loss(self, input_string, output_string):\n",
    "        input_string = self._add_eos(input_string)\n",
    "        output_string = self._add_eos(output_string)\n",
    "\n",
    "        pc.renew_cg()\n",
    "\n",
    "        embedded_string = self._embed_string(input_string)\n",
    "        encoded_string = self._encode_string(embedded_string)\n",
    "\n",
    "        rnn_state = self.DEC_RNN.initial_state().add_input(pc.vecInput(self.enc_state_size))\n",
    "\n",
    "        loss = []\n",
    "        for output_char in output_string:\n",
    "            attended_encoding = self._attend(encoded_string, rnn_state)\n",
    "            rnn_state = rnn_state.add_input(attended_encoding)\n",
    "            loss.append(self.hier_softmax.get_loss(rnn_state.output(), output_char))\n",
    "        loss = pc.esum(loss)\n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    def generate(self, input_string):\n",
    "        input_string = self._add_eos(input_string)\n",
    "\n",
    "        pc.renew_cg()\n",
    "\n",
    "        embedded_string = self._embed_string(input_string)\n",
    "        encoded_string = self._encode_string(embedded_string)\n",
    "\n",
    "        rnn_state = self.DEC_RNN.initial_state().add_input(pc.vecInput(self.enc_state_size))\n",
    "\n",
    "        output_string = []\n",
    "        while True:\n",
    "            attended_encoding = self._attend(encoded_string, rnn_state)\n",
    "            rnn_state = rnn_state.add_input(attended_encoding)\n",
    "            predicted_char = self.self.hier_softmax.generate(rnn_state.output())\n",
    "            output_string.append(predicted_char)\n",
    "            if predicted_char == EOS or len(output_string) > 2*len(input_string):\n",
    "                break\n",
    "        output_string = ' '.join(output_string)\n",
    "        return output_string.replace('<EOS>', '')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:07:28.167242\n",
      "loss on validation set: 1.70575599489\n"
     ]
    }
   ],
   "source": [
    "att = AttentionNetworkWithHierSoftmax(\n",
    "    ENC_RNN_NUM_OF_LAYERS, DEC_RNN_NUM_OF_LAYERS, EMBEDDINGS_SIZE, ENC_STATE_SIZE, DEC_STATE_SIZE, output_tree)\n",
    "\n",
    "train(att, train_set, val_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
